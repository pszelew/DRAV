{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dea9112e-d1b7-4906-8d4d-80f6e9d72e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "import fasttext\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model.encoder import CandidateEncoderConfig\n",
    "from model.decoder import CandidateDecoderConfig\n",
    "from config.general_config import GeneralConfig\n",
    "from trainer.trainer import TrainerConfig\n",
    "from dataset.dataset import SellersDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6141156c-e1e5-42ef-b59f-cb12be4f3efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "with open(\"config/config.yaml\", \"r\") as file:\n",
    "    try:\n",
    "        config = yaml.safe_load(file)[\"vae\"]\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "general_config = GeneralConfig(**{**config[\"general\"]})\n",
    "encoder_config = CandidateEncoderConfig(**{**config[\"encoder\"], **config[\"general\"]})\n",
    "\n",
    "decoder_config = CandidateDecoderConfig(**{**config[\"decoder\"], **config[\"general\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20b27011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import pandas as pd\n",
    "# with open(\"data/test.index\", \"rb\") as f:\n",
    "#     idx = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "# raw_data = pd.read_json(\"data/extracted_sellers_old.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3e54116-216c-4c67-a4f3-4fe8297b5987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset\n",
      "[2022-05-31 02:00:24,495] {dataset.py:138} INFO - Preparing dataset\n",
      "Detecting languages:\n",
      "[2022-05-31 02:00:24,496] {dataset.py:289} INFO - Detecting languages:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56083/56083 [09:07<00:00, 102.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected languages:\n",
      "[2022-05-31 02:09:31,816] {dataset.py:294} INFO - Detected languages:\n",
      "lang\n",
      "UNKNOWN       17\n",
      "af             4\n",
      "ar             1\n",
      "ca             4\n",
      "cy             6\n",
      "da             6\n",
      "de            80\n",
      "en         55243\n",
      "es           192\n",
      "et             1\n",
      "fr            86\n",
      "he             2\n",
      "id             7\n",
      "it           113\n",
      "ja             1\n",
      "lt             1\n",
      "nl            12\n",
      "no             7\n",
      "pl             2\n",
      "pt            13\n",
      "ro             2\n",
      "ru             6\n",
      "sk             2\n",
      "sl             1\n",
      "so             5\n",
      "sw             1\n",
      "tl             4\n",
      "tr             8\n",
      "vi             4\n",
      "NaN            0\n",
      "Name: lang, dtype: int64\n",
      "[2022-05-31 02:09:31,823] {dataset.py:295} INFO - lang\n",
      "UNKNOWN       17\n",
      "af             4\n",
      "ar             1\n",
      "ca             4\n",
      "cy             6\n",
      "da             6\n",
      "de            80\n",
      "en         55243\n",
      "es           192\n",
      "et             1\n",
      "fr            86\n",
      "he             2\n",
      "id             7\n",
      "it           113\n",
      "ja             1\n",
      "lt             1\n",
      "nl            12\n",
      "no             7\n",
      "pl             2\n",
      "pt            13\n",
      "ro             2\n",
      "ru             6\n",
      "sk             2\n",
      "sl             1\n",
      "so             5\n",
      "sw             1\n",
      "tl             4\n",
      "tr             8\n",
      "vi             4\n",
      "NaN            0\n",
      "Name: lang, dtype: int64\n",
      "Removing rows not written in english\n",
      "[2022-05-31 02:09:31,824] {dataset.py:296} INFO - Removing rows not written in english\n",
      "Removed 840 rows\n",
      "[2022-05-31 02:09:31,843] {dataset.py:300} INFO - Removed 840 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 55243/55243 [00:01<00:00, 43675.24it/s]\n",
      "100%|██████████| 55243/55243 [00:00<00:00, 86618.43it/s]\n",
      "100%|██████████| 55243/55243 [00:00<00:00, 67037.19it/s]\n",
      "100%|██████████| 55243/55243 [00:02<00:00, 19349.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding bow for skills_str\n",
      "[2022-05-31 02:09:39,364] {dataset.py:607} INFO - Adding bow for skills_str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding bow for education_str\n",
      "[2022-05-31 02:09:47,147] {dataset.py:607} INFO - Adding bow for education_str\n",
      "Adding language for languages_str\n",
      "[2022-05-31 02:09:51,847] {dataset.py:597} INFO - Adding language for languages_str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55243/55243 [00:00<00:00, 137262.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding language for education_str\n",
      "[2022-05-31 02:09:52,251] {dataset.py:597} INFO - Adding language for education_str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 55243/55243 [00:00<00:00, 81152.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding language for skills_str\n",
      "[2022-05-31 02:09:52,934] {dataset.py:597} INFO - Adding language for skills_str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 55243/55243 [00:01<00:00, 53578.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding language for description_str\n",
      "[2022-05-31 02:09:53,967] {dataset.py:597} INFO - Adding language for description_str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 55243/55243 [00:03<00:00, 15825.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 28331 / 64987 = 0.4359\n",
      "[2022-05-31 02:09:57,466] {language.py:67} INFO - keep_words 28331 / 64987 = 0.4359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 55243/55243 [00:16<00:00, 3288.10it/s]\n",
      "100%|██████████| 55243/55243 [00:09<00:00, 5659.86it/s]\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dataset...\n",
      "[2022-05-31 02:10:25,961] {dataset.py:194} INFO - Saving dataset...\n",
      "Sampling 1000 examples for testing using data/test.index file...\n",
      "[2022-05-31 02:10:26,891] {dataset.py:206} INFO - Sampling 1000 examples for testing using data/test.index file...\n",
      "Removing 1000 test examples from train dataset...\n",
      "[2022-05-31 02:10:26,914] {dataset.py:217} INFO - Removing 1000 test examples from train dataset...\n",
      "Done! Removed 1000 test examples from train dataset\n",
      "[2022-05-31 02:10:26,941] {dataset.py:221} INFO - Done! Removed 1000 test examples from train dataset\n",
      "Done: Saved dataset in data/dataset_fasttext/\n",
      "[2022-05-31 02:10:52,139] {dataset.py:248} INFO - Done: Saved dataset in data/dataset_fasttext/\n"
     ]
    }
   ],
   "source": [
    "dataset = SellersDataset(\n",
    "    dataset_path=\"data/dataset_fasttext/\",\n",
    "    test_index=general_config.test_index,\n",
    "    embedder_name=general_config.embedder_name,\n",
    "    raw_data_path=general_config.raw_data_path,\n",
    "    device=DEVICE,\n",
    "    bow_remove_stopwords=general_config.bow_remove_stopwords,\n",
    "    bow_remove_sentiment=general_config.bow_remove_sentiment,\n",
    "    nn_embedding_size=encoder_config.lstm_hidden_dim,\n",
    "    trim_tr=general_config.trim_tr,\n",
    ")\n",
    "dataset.prepare_dataset(dropna=False)\n",
    "# dataset.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2769bcfc-fb8f-4810-bdbc-9d8345f0c6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54243/54243 [00:49<00:00, 1104.41it/s]\n"
     ]
    }
   ],
   "source": [
    "train_file = \"data/dataset_fasttext/train.txt\"\n",
    "\n",
    "texts = []\n",
    "for idx in tqdm(range(len(dataset))):\n",
    "    texts.append(dataset.get_textual_description(idx))\n",
    "\n",
    "with open(train_file, \"w\") as file:\n",
    "    file.writelines([text + \"\\n\" for text in texts]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cff28239-ea9a-476f-86a7-b0c47bd024a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 4M words\n",
      "Number of words:  14511\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:   51194 lr:  0.000000 avg.loss:  2.042001 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_unsupervised(train_file, minn=3, maxn=6, epoch=5, dim=100)\n",
    "\n",
    "model.save_model(\"model/fasttext/cv.en.100.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2a083d7-d35a-4528-8ca8-68b14f9b7b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8943033218383789, 'microsoft'),\n",
       " (0.8815516233444214, 'word'),\n",
       " (0.8810116052627563, 'msexcel'),\n",
       " (0.8755022883415222, 'office'),\n",
       " (0.8750035166740417, 'entry'),\n",
       " (0.8490250706672668, 'data'),\n",
       " (0.831983745098114, 'typing'),\n",
       " (0.82841956615448, 'msoffice'),\n",
       " (0.811237633228302, 'powerpoint'),\n",
       " (0.8015548586845398, 'spreadsheet')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_nearest_neighbors('excel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8d3e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a62dc5c4e15874d230a4f396bb129d37f109e576af212db1e92385126337577"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
