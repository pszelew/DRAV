{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First attempt to create a new representation method for a candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from model.encoder import CandidateEncoderConfig\n",
    "from model.decoder import CandidateDecoderConfig\n",
    "from model.candidate_vae import CandidateVAE\n",
    "from trainer.trainer import BetaVaeTrainer, TrainerConfig\n",
    "from config.general_config import GeneralConfig\n",
    "from dataset.utils import pad_collate\n",
    "from dataset.dataset import SellersDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "with open(\"config/config.yaml\", \"r\") as file:\n",
    "    try:\n",
    "        config = yaml.safe_load(file)[\"vae\"]\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "general_config = GeneralConfig(**config[\"general\"])\n",
    "encoder_config = CandidateEncoderConfig(**{**config[\"encoder\"], **config[\"general\"]})\n",
    "\n",
    "decoder_config = CandidateDecoderConfig(**{**config[\"decoder\"], **config[\"general\"]})\n",
    "\n",
    "trainer_config = TrainerConfig(**{**config[\"trainer\"], **config[\"general\"]})\n",
    "\n",
    "log_dir = os.path.join(general_config.checkpoints_dir, \"runs\")\n",
    "\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "writer_tensorboard = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset data/dataset/...\n",
      "[2022-06-02 07:42:17,769] {dataset.py:251} INFO - Loading dataset data/dataset/...\n",
      "Loaded dataset data/dataset/!\n",
      "[2022-06-02 07:42:19,792] {dataset.py:279} INFO - Loaded dataset data/dataset/!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "dataset = SellersDataset(\n",
    "    dataset_path=general_config.datset_path,\n",
    "    test_index=general_config.dataset,\n",
    "    embedder_name=general_config.embedder_name,\n",
    "    raw_data_path=general_config.raw_data_path,\n",
    "    device=DEVICE,\n",
    "    bow_remove_stopwords=general_config.bow_remove_stopwords,\n",
    "    bow_remove_sentiment=general_config.bow_remove_sentiment,\n",
    "    nn_embedding_size=encoder_config.lstm_hidden_dim,\n",
    "    trim_tr=general_config.trim_tr,\n",
    ")\n",
    "# dataset.prepare_dataset()\n",
    "dataset.load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=general_config.batch_size,\n",
    "    collate_fn=pad_collate(dataset.vocab.pad_token),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models to test them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_vae = CandidateVAE(\n",
    "    general_config, encoder_config, decoder_config, dataset.vocab, dataset.embedder\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BetaVaeTrainer...\n",
      "[2022-06-02 07:42:23,548] {trainer.py:246} INFO - Initializing BetaVaeTrainer...\n",
      "Done: BetaVaeTrainer initialized!\n",
      "[2022-06-02 07:42:23,561] {trainer.py:358} INFO - Done: BetaVaeTrainer initialized!\n"
     ]
    }
   ],
   "source": [
    "trainer = BetaVaeTrainer(\n",
    "    candidate_vae,\n",
    "    general_config,\n",
    "    trainer_config,\n",
    "    dataloader,\n",
    "    writer_tensorboard,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loop...\n",
      "[2022-06-01 15:09:13,978] {trainer.py:741} INFO - Training loop...\n",
      "Epoch 1/6\n",
      "[2022-06-01 15:09:13,979] {trainer.py:743} INFO - Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1251/1251 [33:49<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/6\n",
      "[2022-06-01 15:43:03,646] {trainer.py:743} INFO - Epoch 2/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1251/1251 [33:27<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/6\n",
      "[2022-06-01 16:16:31,045] {trainer.py:743} INFO - Epoch 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1251/1251 [34:32<00:00,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/6\n",
      "[2022-06-01 16:51:03,054] {trainer.py:743} INFO - Epoch 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1251/1251 [31:40<00:00,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/6\n",
      "[2022-06-01 17:22:43,920] {trainer.py:743} INFO - Epoch 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1251/1251 [34:37<00:00,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/6\n",
      "[2022-06-01 17:57:21,341] {trainer.py:743} INFO - Epoch 6/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1251/1251 [29:30<00:00,  1.42s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a62dc5c4e15874d230a4f396bb129d37f109e576af212db1e92385126337577"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
