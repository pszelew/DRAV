{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test capacity control\n",
    "\n",
    "Test if we can infer about certain type of competences using only the desired part of latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from model.encoder import CandidateEncoderConfig\n",
    "from model.decoder import CandidateDecoderConfig\n",
    "from model.candidate_vae import CandidateVAE\n",
    "from trainer.trainer import TrainerConfig\n",
    "from config.general_config import GeneralConfig\n",
    "from dataset.dataset import SellersDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT = \"candidate_vae_02_06_22_04_13_30\"\n",
    "CHECKPOINT = \"7506_checkpoint.tar\"\n",
    "# If false, we can used cached content e.g. if we are testing the code\n",
    "CREATE_DATASET = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "with open(os.path.join(\"checkpoints\", EXPERIMENT, \"config.yaml\"), \"r\") as file:\n",
    "    try:\n",
    "        config = yaml.safe_load(file)[\"vae\"]\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "general_config = GeneralConfig(**config[\"general\"])\n",
    "\n",
    "\n",
    "encoder_config = CandidateEncoderConfig(**{**config[\"encoder\"], **config[\"general\"]})\n",
    "\n",
    "decoder_config = CandidateDecoderConfig(**{**config[\"decoder\"], **config[\"general\"]})\n",
    "\n",
    "trainer_config = TrainerConfig(**{**config[\"trainer\"], **config[\"general\"]})\n",
    "\n",
    "log_dir = os.path.join(general_config.checkpoints_dir, \"runs\")\n",
    "\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "writer_tensorboard = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reload_ext tensorboard\n",
    "# %tensorboard --logdir $log_dir --port=6008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset data/dataset_2/...\n",
      "[2022-06-04 11:17:23,429] {dataset.py:260} INFO - Loading dataset data/dataset_2/...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset data/dataset_2/!\n",
      "[2022-06-04 11:17:24,209] {dataset.py:288} INFO - Loaded dataset data/dataset_2/!\n"
     ]
    }
   ],
   "source": [
    "dataset = SellersDataset(\n",
    "    dataset_path=general_config.datset_path,\n",
    "    test_index=general_config.test_index,\n",
    "    embedder_name=general_config.embedder_name,\n",
    "    raw_data_path=general_config.raw_data_path,\n",
    "    device=DEVICE,\n",
    "    bow_remove_stopwords=general_config.bow_remove_stopwords,\n",
    "    bow_remove_sentiment=general_config.bow_remove_sentiment,\n",
    "    nn_embedding_size=encoder_config.lstm_hidden_dim,\n",
    "    trim_tr=general_config.trim_tr,\n",
    ")\n",
    "# dataset.prepare_dataset()\n",
    "dataset.load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent space configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "disentangled_targets = {\n",
    "    \"skills\": {\n",
    "        \"latent_dim\": trainer_config.skills_dim,\n",
    "        \"output_dim\": dataset.bow_vocab.n_words,\n",
    "        \"indexes\": (0, trainer_config.skills_dim),\n",
    "    },\n",
    "    \"education\": {\n",
    "        \"latent_dim\": trainer_config.education_dim,\n",
    "        \"output_dim\": dataset.bow_vocab.n_words,\n",
    "        \"indexes\": (\n",
    "            trainer_config.skills_dim,\n",
    "            trainer_config.skills_dim + trainer_config.education_dim,\n",
    "        ),\n",
    "    },\n",
    "    \"languages\": {\n",
    "        \"latent_dim\": trainer_config.languages_dim,\n",
    "        \"output_dim\": len(dataset.langs_map) * dataset.num_lang_levels,\n",
    "        \"indexes\": (\n",
    "            trainer_config.skills_dim + trainer_config.education_dim,\n",
    "            trainer_config.skills_dim\n",
    "            + trainer_config.education_dim\n",
    "            + trainer_config.languages_dim,\n",
    "        ),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(os.path.join(\"checkpoints\", EXPERIMENT, CHECKPOINT))\n",
    "\n",
    "candidate_vae = CandidateVAE(\n",
    "    general_config, encoder_config, decoder_config, dataset.vocab, dataset.embedder\n",
    ").to(DEVICE)\n",
    "\n",
    "candidate_vae.encoder.load_state_dict(checkpoint[\"encoder\"])\n",
    "candidate_vae.decoder.load_state_dict(checkpoint[\"decoder\"])\n",
    "candidate_vae.embedding.load_state_dict(checkpoint[\"embedding\"]) if checkpoint[\n",
    "    \"embedding\"\n",
    "] else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CandidateVAE(\n",
       "  (encoder): CandidateEncoder(\n",
       "    (lstm): LSTM(100, 64, bidirectional=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (relu): ReLU()\n",
       "    (fcs): ModuleList(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    )\n",
       "    (fc_mu): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (fc_var): Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (decoder): CandidateDecoder(\n",
       "    (lstm): LSTM(100, 64)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (relu): ReLU()\n",
       "    (fcs): ModuleList(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): Linear(in_features=64, out_features=100, bias=True)\n",
       "    )\n",
       "    (attn): Attn()\n",
       "    (attn_mu): Identity()\n",
       "    (attn_var): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (concat): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (out): Linear(in_features=64, out_features=28371, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_vae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare train test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_rows(dataset: SellersDataset) -> dict:\n",
    "    rows = []\n",
    "\n",
    "    for idx in tqdm(range(len(dataset))):\n",
    "        latents = {}\n",
    "        # Both seeds have to me set up!!!\n",
    "        rng = np.random.default_rng(42)\n",
    "        random.seed(42)\n",
    "        row = dataset.__getitem__(idx)\n",
    "        targets = {}\n",
    "\n",
    "        (\n",
    "            input_tensor,\n",
    "            _,\n",
    "            targets[\"skills\"],\n",
    "            targets[\"education\"],\n",
    "            targets[\"languages\"],\n",
    "        ) = row\n",
    "\n",
    "        with torch.no_grad():\n",
    "            input_lengths = torch.tensor(len(input_tensor)).unsqueeze(dim=0)\n",
    "\n",
    "            mu, var, outputs, (hn, cn) = candidate_vae.encoder(\n",
    "                input_tensor.unsqueeze(dim=1).to(DEVICE), input_lengths.to(\"cpu\")\n",
    "            )\n",
    "            z = candidate_vae.decoder.reparameterize(mu, var)\n",
    "\n",
    "        for key in disentangled_targets:\n",
    "            index_start, index_end = disentangled_targets[key][\"indexes\"]\n",
    "\n",
    "            # Use mu or z?\n",
    "            latents[key] = [\n",
    "                z[:, index_start:index_end],\n",
    "                torch.cat(\n",
    "                    (z[:, :index_start], z[:, index_end:]),\n",
    "                    dim=1,\n",
    "                ),\n",
    "                targets[key],\n",
    "            ]\n",
    "\n",
    "        rows.append(latents)\n",
    "    return rows\n",
    "\n",
    "\n",
    "def prepare_test_data(dataset: SellersDataset):\n",
    "    # We have to set both seeds!!!\n",
    "    rng = np.random.default_rng(42)\n",
    "    random.seed(42)\n",
    "\n",
    "    texts = dataset.test_dataset.progress_apply(\n",
    "        lambda x: dataset._create_textual_decription(x, rng), axis=1\n",
    "    )\n",
    "    embedded = [dataset.embedder(text)[0].cpu() for text in tqdm(texts)]\n",
    "\n",
    "    # if general_config.embedder_name != EmbedderType.LANG:\n",
    "    embedded = [text.unsqueeze(dim=1) for text in tqdm(embedded)]\n",
    "\n",
    "    input_lengths = [torch.tensor(len(row)).unsqueeze(dim=0) for row in embedded]\n",
    "\n",
    "    dataset.test_dataset[\"embedded\"] = embedded\n",
    "    dataset.test_dataset[\"input_lengths\"] = input_lengths\n",
    "\n",
    "\n",
    "def prepare_test_row(row: pd.Series) -> dict:\n",
    "    latents = {}\n",
    "    with torch.no_grad():\n",
    "        mu, var, outputs, (hn, cn) = candidate_vae.encoder(\n",
    "            row[\"embedded\"].to(DEVICE), row[\"input_lengths\"].to(\"cpu\")\n",
    "        )\n",
    "        z = candidate_vae.decoder.reparameterize(mu, var)\n",
    "\n",
    "    for key in disentangled_targets:\n",
    "        index_start, index_end = disentangled_targets[key][\"indexes\"]\n",
    "\n",
    "        # Use mu or z?        \n",
    "        latents[key] = [\n",
    "            z[:, index_start:index_end],\n",
    "            torch.cat(\n",
    "                (z[:, :index_start], z[:, index_end:]),\n",
    "                dim=1,\n",
    "            ),\n",
    "            row[f\"{key}_vec\"],\n",
    "        ]\n",
    "\n",
    "    return latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 59/40014 [00:00<02:16, 293.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([85, 1, 100])\n",
      "torch.Size([87, 1, 100])\n",
      "torch.Size([79, 1, 100])\n",
      "torch.Size([89, 1, 100])\n",
      "torch.Size([70, 1, 100])\n",
      "torch.Size([63, 1, 100])\n",
      "torch.Size([127, 1, 100])\n",
      "torch.Size([117, 1, 100])\n",
      "torch.Size([72, 1, 100])\n",
      "torch.Size([80, 1, 100])\n",
      "torch.Size([131, 1, 100])\n",
      "torch.Size([109, 1, 100])\n",
      "torch.Size([78, 1, 100])\n",
      "torch.Size([112, 1, 100])\n",
      "torch.Size([46, 1, 100])\n",
      "torch.Size([133, 1, 100])\n",
      "torch.Size([126, 1, 100])\n",
      "torch.Size([77, 1, 100])\n",
      "torch.Size([143, 1, 100])\n",
      "torch.Size([65, 1, 100])\n",
      "torch.Size([121, 1, 100])\n",
      "torch.Size([141, 1, 100])\n",
      "torch.Size([81, 1, 100])\n",
      "torch.Size([157, 1, 100])\n",
      "torch.Size([146, 1, 100])\n",
      "torch.Size([53, 1, 100])\n",
      "torch.Size([122, 1, 100])\n",
      "torch.Size([43, 1, 100])\n",
      "torch.Size([122, 1, 100])\n",
      "torch.Size([88, 1, 100])\n",
      "torch.Size([100, 1, 100])\n",
      "torch.Size([56, 1, 100])\n",
      "torch.Size([125, 1, 100])\n",
      "torch.Size([142, 1, 100])\n",
      "torch.Size([114, 1, 100])\n",
      "torch.Size([109, 1, 100])\n",
      "torch.Size([62, 1, 100])\n",
      "torch.Size([82, 1, 100])\n",
      "torch.Size([123, 1, 100])\n",
      "torch.Size([66, 1, 100])\n",
      "torch.Size([103, 1, 100])\n",
      "torch.Size([81, 1, 100])\n",
      "torch.Size([112, 1, 100])\n",
      "torch.Size([92, 1, 100])\n",
      "torch.Size([64, 1, 100])\n",
      "torch.Size([62, 1, 100])\n",
      "torch.Size([98, 1, 100])\n",
      "torch.Size([86, 1, 100])\n",
      "torch.Size([90, 1, 100])\n",
      "torch.Size([134, 1, 100])\n",
      "torch.Size([89, 1, 100])\n",
      "torch.Size([98, 1, 100])\n",
      "torch.Size([92, 1, 100])\n",
      "torch.Size([97, 1, 100])\n",
      "torch.Size([107, 1, 100])\n",
      "torch.Size([128, 1, 100])\n",
      "torch.Size([61, 1, 100])\n",
      "torch.Size([133, 1, 100])\n",
      "torch.Size([115, 1, 100])\n",
      "torch.Size([65, 1, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 124/40014 [00:00<02:07, 311.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([103, 1, 100])\n",
      "torch.Size([84, 1, 100])\n",
      "torch.Size([116, 1, 100])\n",
      "torch.Size([94, 1, 100])\n",
      "torch.Size([100, 1, 100])\n",
      "torch.Size([76, 1, 100])\n",
      "torch.Size([61, 1, 100])\n",
      "torch.Size([51, 1, 100])\n",
      "torch.Size([110, 1, 100])\n",
      "torch.Size([94, 1, 100])\n",
      "torch.Size([123, 1, 100])\n",
      "torch.Size([56, 1, 100])\n",
      "torch.Size([123, 1, 100])\n",
      "torch.Size([60, 1, 100])\n",
      "torch.Size([100, 1, 100])\n",
      "torch.Size([71, 1, 100])\n",
      "torch.Size([93, 1, 100])\n",
      "torch.Size([56, 1, 100])\n",
      "torch.Size([64, 1, 100])\n",
      "torch.Size([63, 1, 100])\n",
      "torch.Size([138, 1, 100])\n",
      "torch.Size([141, 1, 100])\n",
      "torch.Size([99, 1, 100])\n",
      "torch.Size([69, 1, 100])\n",
      "torch.Size([104, 1, 100])\n",
      "torch.Size([89, 1, 100])\n",
      "torch.Size([118, 1, 100])\n",
      "torch.Size([84, 1, 100])\n",
      "torch.Size([103, 1, 100])\n",
      "torch.Size([128, 1, 100])\n",
      "torch.Size([92, 1, 100])\n",
      "torch.Size([73, 1, 100])\n",
      "torch.Size([94, 1, 100])\n",
      "torch.Size([120, 1, 100])\n",
      "torch.Size([146, 1, 100])\n",
      "torch.Size([138, 1, 100])\n",
      "torch.Size([100, 1, 100])\n",
      "torch.Size([132, 1, 100])\n",
      "torch.Size([69, 1, 100])\n",
      "torch.Size([92, 1, 100])\n",
      "torch.Size([55, 1, 100])\n",
      "torch.Size([112, 1, 100])\n",
      "torch.Size([58, 1, 100])\n",
      "torch.Size([140, 1, 100])\n",
      "torch.Size([113, 1, 100])\n",
      "torch.Size([65, 1, 100])\n",
      "torch.Size([71, 1, 100])\n",
      "torch.Size([52, 1, 100])\n",
      "torch.Size([57, 1, 100])\n",
      "torch.Size([129, 1, 100])\n",
      "torch.Size([59, 1, 100])\n",
      "torch.Size([81, 1, 100])\n",
      "torch.Size([112, 1, 100])\n",
      "torch.Size([69, 1, 100])\n",
      "torch.Size([60, 1, 100])\n",
      "torch.Size([115, 1, 100])\n",
      "torch.Size([71, 1, 100])\n",
      "torch.Size([61, 1, 100])\n",
      "torch.Size([75, 1, 100])\n",
      "torch.Size([124, 1, 100])\n",
      "torch.Size([51, 1, 100])\n",
      "torch.Size([155, 1, 100])\n",
      "torch.Size([71, 1, 100])\n",
      "torch.Size([72, 1, 100])\n",
      "torch.Size([126, 1, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 156/40014 [00:00<02:07, 313.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([63, 1, 100])\n",
      "torch.Size([83, 1, 100])\n",
      "torch.Size([127, 1, 100])\n",
      "torch.Size([129, 1, 100])\n",
      "torch.Size([70, 1, 100])\n",
      "torch.Size([50, 1, 100])\n",
      "torch.Size([168, 1, 100])\n",
      "torch.Size([73, 1, 100])\n",
      "torch.Size([88, 1, 100])\n",
      "torch.Size([102, 1, 100])\n",
      "torch.Size([115, 1, 100])\n",
      "torch.Size([143, 1, 100])\n",
      "torch.Size([122, 1, 100])\n",
      "torch.Size([92, 1, 100])\n",
      "torch.Size([86, 1, 100])\n",
      "torch.Size([72, 1, 100])\n",
      "torch.Size([91, 1, 100])\n",
      "torch.Size([116, 1, 100])\n",
      "torch.Size([123, 1, 100])\n",
      "torch.Size([97, 1, 100])\n",
      "torch.Size([90, 1, 100])\n",
      "torch.Size([62, 1, 100])\n",
      "torch.Size([45, 1, 100])\n",
      "torch.Size([64, 1, 100])\n",
      "torch.Size([84, 1, 100])\n",
      "torch.Size([83, 1, 100])\n",
      "torch.Size([97, 1, 100])\n",
      "torch.Size([86, 1, 100])\n",
      "torch.Size([73, 1, 100])\n",
      "torch.Size([100, 1, 100])\n",
      "torch.Size([84, 1, 100])\n",
      "torch.Size([133, 1, 100])\n",
      "torch.Size([69, 1, 100])\n",
      "torch.Size([141, 1, 100])\n",
      "torch.Size([134, 1, 100])\n",
      "torch.Size([116, 1, 100])\n",
      "torch.Size([95, 1, 100])\n",
      "torch.Size([109, 1, 100])\n",
      "torch.Size([81, 1, 100])\n",
      "torch.Size([112, 1, 100])\n",
      "torch.Size([191, 1, 100])\n",
      "torch.Size([135, 1, 100])\n",
      "torch.Size([101, 1, 100])\n",
      "torch.Size([149, 1, 100])\n",
      "torch.Size([134, 1, 100])\n",
      "torch.Size([53, 1, 100])\n",
      "torch.Size([87, 1, 100])\n",
      "torch.Size([147, 1, 100])\n",
      "torch.Size([108, 1, 100])\n",
      "torch.Size([78, 1, 100])\n",
      "torch.Size([88, 1, 100])\n",
      "torch.Size([74, 1, 100])\n",
      "torch.Size([79, 1, 100])\n",
      "torch.Size([61, 1, 100])\n",
      "torch.Size([64, 1, 100])\n",
      "torch.Size([89, 1, 100])\n",
      "torch.Size([103, 1, 100])\n",
      "torch.Size([112, 1, 100])\n",
      "torch.Size([95, 1, 100])\n",
      "torch.Size([62, 1, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 219/40014 [00:00<02:11, 303.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([55, 1, 100])\n",
      "torch.Size([100, 1, 100])\n",
      "torch.Size([73, 1, 100])\n",
      "torch.Size([127, 1, 100])\n",
      "torch.Size([111, 1, 100])\n",
      "torch.Size([50, 1, 100])\n",
      "torch.Size([67, 1, 100])\n",
      "torch.Size([145, 1, 100])\n",
      "torch.Size([110, 1, 100])\n",
      "torch.Size([146, 1, 100])\n",
      "torch.Size([57, 1, 100])\n",
      "torch.Size([108, 1, 100])\n",
      "torch.Size([101, 1, 100])\n",
      "torch.Size([79, 1, 100])\n",
      "torch.Size([78, 1, 100])\n",
      "torch.Size([60, 1, 100])\n",
      "torch.Size([98, 1, 100])\n",
      "torch.Size([104, 1, 100])\n",
      "torch.Size([80, 1, 100])\n",
      "torch.Size([86, 1, 100])\n",
      "torch.Size([57, 1, 100])\n",
      "torch.Size([114, 1, 100])\n",
      "torch.Size([53, 1, 100])\n",
      "torch.Size([118, 1, 100])\n",
      "torch.Size([125, 1, 100])\n",
      "torch.Size([97, 1, 100])\n",
      "torch.Size([91, 1, 100])\n",
      "torch.Size([88, 1, 100])\n",
      "torch.Size([84, 1, 100])\n",
      "torch.Size([59, 1, 100])\n",
      "torch.Size([117, 1, 100])\n",
      "torch.Size([92, 1, 100])\n",
      "torch.Size([93, 1, 100])\n",
      "torch.Size([65, 1, 100])\n",
      "torch.Size([84, 1, 100])\n",
      "torch.Size([129, 1, 100])\n",
      "torch.Size([62, 1, 100])\n",
      "torch.Size([129, 1, 100])\n",
      "torch.Size([44, 1, 100])\n",
      "torch.Size([137, 1, 100])\n",
      "torch.Size([118, 1, 100])\n",
      "torch.Size([69, 1, 100])\n",
      "torch.Size([115, 1, 100])\n",
      "torch.Size([126, 1, 100])\n",
      "torch.Size([130, 1, 100])\n",
      "torch.Size([64, 1, 100])\n",
      "torch.Size([105, 1, 100])\n",
      "torch.Size([65, 1, 100])\n",
      "torch.Size([54, 1, 100])\n",
      "torch.Size([76, 1, 100])\n",
      "torch.Size([86, 1, 100])\n",
      "torch.Size([143, 1, 100])\n",
      "torch.Size([74, 1, 100])\n",
      "torch.Size([67, 1, 100])\n",
      "torch.Size([132, 1, 100])\n",
      "torch.Size([114, 1, 100])\n",
      "torch.Size([87, 1, 100])\n",
      "torch.Size([116, 1, 100])\n",
      "torch.Size([93, 1, 100])\n",
      "torch.Size([80, 1, 100])\n",
      "torch.Size([144, 1, 100])\n",
      "torch.Size([65, 1, 100])\n",
      "torch.Size([121, 1, 100])\n",
      "torch.Size([121, 1, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 283/40014 [00:00<02:15, 293.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([57, 1, 100])\n",
      "torch.Size([85, 1, 100])\n",
      "torch.Size([101, 1, 100])\n",
      "torch.Size([70, 1, 100])\n",
      "torch.Size([143, 1, 100])\n",
      "torch.Size([109, 1, 100])\n",
      "torch.Size([88, 1, 100])\n",
      "torch.Size([135, 1, 100])\n",
      "torch.Size([55, 1, 100])\n",
      "torch.Size([115, 1, 100])\n",
      "torch.Size([73, 1, 100])\n",
      "torch.Size([109, 1, 100])\n",
      "torch.Size([107, 1, 100])\n",
      "torch.Size([127, 1, 100])\n",
      "torch.Size([50, 1, 100])\n",
      "torch.Size([45, 1, 100])\n",
      "torch.Size([123, 1, 100])\n",
      "torch.Size([68, 1, 100])\n",
      "torch.Size([85, 1, 100])\n",
      "torch.Size([170, 1, 100])\n",
      "torch.Size([127, 1, 100])\n",
      "torch.Size([113, 1, 100])\n",
      "torch.Size([103, 1, 100])\n",
      "torch.Size([81, 1, 100])\n",
      "torch.Size([51, 1, 100])\n",
      "torch.Size([64, 1, 100])\n",
      "torch.Size([94, 1, 100])\n",
      "torch.Size([107, 1, 100])\n",
      "torch.Size([145, 1, 100])\n",
      "torch.Size([80, 1, 100])\n",
      "torch.Size([79, 1, 100])\n",
      "torch.Size([78, 1, 100])\n",
      "torch.Size([100, 1, 100])\n",
      "torch.Size([60, 1, 100])\n",
      "torch.Size([83, 1, 100])\n",
      "torch.Size([94, 1, 100])\n",
      "torch.Size([98, 1, 100])\n",
      "torch.Size([84, 1, 100])\n",
      "torch.Size([90, 1, 100])\n",
      "torch.Size([69, 1, 100])\n",
      "torch.Size([65, 1, 100])\n",
      "torch.Size([79, 1, 100])\n",
      "torch.Size([106, 1, 100])\n",
      "torch.Size([112, 1, 100])\n",
      "torch.Size([99, 1, 100])\n",
      "torch.Size([51, 1, 100])\n",
      "torch.Size([66, 1, 100])\n",
      "torch.Size([142, 1, 100])\n",
      "torch.Size([113, 1, 100])\n",
      "torch.Size([60, 1, 100])\n",
      "torch.Size([47, 1, 100])\n",
      "torch.Size([104, 1, 100])\n",
      "torch.Size([99, 1, 100])\n",
      "torch.Size([140, 1, 100])\n",
      "torch.Size([114, 1, 100])\n",
      "torch.Size([80, 1, 100])\n",
      "torch.Size([54, 1, 100])\n",
      "torch.Size([60, 1, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 344/40014 [00:01<02:15, 292.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([125, 1, 100])\n",
      "torch.Size([117, 1, 100])\n",
      "torch.Size([91, 1, 100])\n",
      "torch.Size([116, 1, 100])\n",
      "torch.Size([93, 1, 100])\n",
      "torch.Size([105, 1, 100])\n",
      "torch.Size([124, 1, 100])\n",
      "torch.Size([140, 1, 100])\n",
      "torch.Size([98, 1, 100])\n",
      "torch.Size([100, 1, 100])\n",
      "torch.Size([121, 1, 100])\n",
      "torch.Size([137, 1, 100])\n",
      "torch.Size([92, 1, 100])\n",
      "torch.Size([50, 1, 100])\n",
      "torch.Size([91, 1, 100])\n",
      "torch.Size([96, 1, 100])\n",
      "torch.Size([70, 1, 100])\n",
      "torch.Size([121, 1, 100])\n",
      "torch.Size([116, 1, 100])\n",
      "torch.Size([76, 1, 100])\n",
      "torch.Size([73, 1, 100])\n",
      "torch.Size([118, 1, 100])\n",
      "torch.Size([138, 1, 100])\n",
      "torch.Size([57, 1, 100])\n",
      "torch.Size([87, 1, 100])\n",
      "torch.Size([71, 1, 100])\n",
      "torch.Size([60, 1, 100])\n",
      "torch.Size([60, 1, 100])\n",
      "torch.Size([110, 1, 100])\n",
      "torch.Size([152, 1, 100])\n",
      "torch.Size([73, 1, 100])\n",
      "torch.Size([49, 1, 100])\n",
      "torch.Size([50, 1, 100])\n",
      "torch.Size([93, 1, 100])\n",
      "torch.Size([73, 1, 100])\n",
      "torch.Size([147, 1, 100])\n",
      "torch.Size([101, 1, 100])\n",
      "torch.Size([110, 1, 100])\n",
      "torch.Size([68, 1, 100])\n",
      "torch.Size([143, 1, 100])\n",
      "torch.Size([126, 1, 100])\n",
      "torch.Size([89, 1, 100])\n",
      "torch.Size([109, 1, 100])\n",
      "torch.Size([55, 1, 100])\n",
      "torch.Size([95, 1, 100])\n",
      "torch.Size([128, 1, 100])\n",
      "torch.Size([134, 1, 100])\n",
      "torch.Size([93, 1, 100])\n",
      "torch.Size([77, 1, 100])\n",
      "torch.Size([62, 1, 100])\n",
      "torch.Size([91, 1, 100])\n",
      "torch.Size([72, 1, 100])\n",
      "torch.Size([148, 1, 100])\n",
      "torch.Size([46, 1, 100])\n",
      "torch.Size([131, 1, 100])\n",
      "torch.Size([41, 1, 100])\n",
      "torch.Size([144, 1, 100])\n",
      "torch.Size([43, 1, 100])\n",
      "torch.Size([111, 1, 100])\n",
      "torch.Size([71, 1, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 407/40014 [00:01<02:11, 300.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([105, 1, 100])\n",
      "torch.Size([51, 1, 100])\n",
      "torch.Size([48, 1, 100])\n",
      "torch.Size([63, 1, 100])\n",
      "torch.Size([64, 1, 100])\n",
      "torch.Size([124, 1, 100])\n",
      "torch.Size([117, 1, 100])\n",
      "torch.Size([112, 1, 100])\n",
      "torch.Size([129, 1, 100])\n",
      "torch.Size([79, 1, 100])\n",
      "torch.Size([217, 1, 100])\n",
      "torch.Size([89, 1, 100])\n",
      "torch.Size([89, 1, 100])\n",
      "torch.Size([114, 1, 100])\n",
      "torch.Size([107, 1, 100])\n",
      "torch.Size([96, 1, 100])\n",
      "torch.Size([129, 1, 100])\n",
      "torch.Size([81, 1, 100])\n",
      "torch.Size([64, 1, 100])\n",
      "torch.Size([123, 1, 100])\n",
      "torch.Size([116, 1, 100])\n",
      "torch.Size([106, 1, 100])\n",
      "torch.Size([81, 1, 100])\n",
      "torch.Size([58, 1, 100])\n",
      "torch.Size([117, 1, 100])\n",
      "torch.Size([127, 1, 100])\n",
      "torch.Size([79, 1, 100])\n",
      "torch.Size([114, 1, 100])\n",
      "torch.Size([108, 1, 100])\n",
      "torch.Size([85, 1, 100])\n",
      "torch.Size([72, 1, 100])\n",
      "torch.Size([122, 1, 100])\n",
      "torch.Size([108, 1, 100])\n",
      "torch.Size([83, 1, 100])\n",
      "torch.Size([80, 1, 100])\n",
      "torch.Size([71, 1, 100])\n",
      "torch.Size([79, 1, 100])\n",
      "torch.Size([117, 1, 100])\n",
      "torch.Size([50, 1, 100])\n",
      "torch.Size([124, 1, 100])\n",
      "torch.Size([60, 1, 100])\n",
      "torch.Size([95, 1, 100])\n",
      "torch.Size([89, 1, 100])\n",
      "torch.Size([127, 1, 100])\n",
      "torch.Size([89, 1, 100])\n",
      "torch.Size([83, 1, 100])\n",
      "torch.Size([96, 1, 100])\n",
      "torch.Size([129, 1, 100])\n",
      "torch.Size([109, 1, 100])\n",
      "torch.Size([142, 1, 100])\n",
      "torch.Size([118, 1, 100])\n",
      "torch.Size([100, 1, 100])\n",
      "torch.Size([88, 1, 100])\n",
      "torch.Size([67, 1, 100])\n",
      "torch.Size([125, 1, 100])\n",
      "torch.Size([116, 1, 100])\n",
      "torch.Size([97, 1, 100])\n",
      "torch.Size([109, 1, 100])\n",
      "torch.Size([91, 1, 100])\n",
      "torch.Size([122, 1, 100])\n",
      "torch.Size([66, 1, 100])\n",
      "torch.Size([91, 1, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 468/40014 [00:01<02:12, 297.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([101, 1, 100])\n",
      "torch.Size([118, 1, 100])\n",
      "torch.Size([67, 1, 100])\n",
      "torch.Size([59, 1, 100])\n",
      "torch.Size([81, 1, 100])\n",
      "torch.Size([121, 1, 100])\n",
      "torch.Size([74, 1, 100])\n",
      "torch.Size([119, 1, 100])\n",
      "torch.Size([103, 1, 100])\n",
      "torch.Size([120, 1, 100])\n",
      "torch.Size([61, 1, 100])\n",
      "torch.Size([119, 1, 100])\n",
      "torch.Size([124, 1, 100])\n",
      "torch.Size([118, 1, 100])\n",
      "torch.Size([98, 1, 100])\n",
      "torch.Size([108, 1, 100])\n",
      "torch.Size([85, 1, 100])\n",
      "torch.Size([76, 1, 100])\n",
      "torch.Size([76, 1, 100])\n",
      "torch.Size([74, 1, 100])\n",
      "torch.Size([78, 1, 100])\n",
      "torch.Size([131, 1, 100])\n",
      "torch.Size([117, 1, 100])\n",
      "torch.Size([80, 1, 100])\n",
      "torch.Size([59, 1, 100])\n",
      "torch.Size([118, 1, 100])\n",
      "torch.Size([103, 1, 100])\n",
      "torch.Size([106, 1, 100])\n",
      "torch.Size([81, 1, 100])\n",
      "torch.Size([91, 1, 100])\n",
      "torch.Size([80, 1, 100])\n",
      "torch.Size([144, 1, 100])\n",
      "torch.Size([89, 1, 100])\n",
      "torch.Size([116, 1, 100])\n",
      "torch.Size([89, 1, 100])\n",
      "torch.Size([120, 1, 100])\n",
      "torch.Size([83, 1, 100])\n",
      "torch.Size([84, 1, 100])\n",
      "torch.Size([126, 1, 100])\n",
      "torch.Size([207, 1, 100])\n",
      "torch.Size([106, 1, 100])\n",
      "torch.Size([61, 1, 100])\n",
      "torch.Size([134, 1, 100])\n",
      "torch.Size([116, 1, 100])\n",
      "torch.Size([112, 1, 100])\n",
      "torch.Size([109, 1, 100])\n",
      "torch.Size([103, 1, 100])\n",
      "torch.Size([104, 1, 100])\n",
      "torch.Size([117, 1, 100])\n",
      "torch.Size([95, 1, 100])\n",
      "torch.Size([99, 1, 100])\n",
      "torch.Size([117, 1, 100])\n",
      "torch.Size([48, 1, 100])\n",
      "torch.Size([139, 1, 100])\n",
      "torch.Size([115, 1, 100])\n",
      "torch.Size([108, 1, 100])\n",
      "torch.Size([68, 1, 100])\n",
      "torch.Size([72, 1, 100])\n",
      "torch.Size([78, 1, 100])\n",
      "torch.Size([135, 1, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 531/40014 [00:01<02:10, 301.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([65, 1, 100])\n",
      "torch.Size([85, 1, 100])\n",
      "torch.Size([137, 1, 100])\n",
      "torch.Size([104, 1, 100])\n",
      "torch.Size([67, 1, 100])\n",
      "torch.Size([91, 1, 100])\n",
      "torch.Size([99, 1, 100])\n",
      "torch.Size([70, 1, 100])\n",
      "torch.Size([93, 1, 100])\n",
      "torch.Size([91, 1, 100])\n",
      "torch.Size([99, 1, 100])\n",
      "torch.Size([104, 1, 100])\n",
      "torch.Size([37, 1, 100])\n",
      "torch.Size([121, 1, 100])\n",
      "torch.Size([85, 1, 100])\n",
      "torch.Size([85, 1, 100])\n",
      "torch.Size([93, 1, 100])\n",
      "torch.Size([60, 1, 100])\n",
      "torch.Size([107, 1, 100])\n",
      "torch.Size([121, 1, 100])\n",
      "torch.Size([64, 1, 100])\n",
      "torch.Size([76, 1, 100])\n",
      "torch.Size([99, 1, 100])\n",
      "torch.Size([65, 1, 100])\n",
      "torch.Size([78, 1, 100])\n",
      "torch.Size([131, 1, 100])\n",
      "torch.Size([51, 1, 100])\n",
      "torch.Size([68, 1, 100])\n",
      "torch.Size([58, 1, 100])\n",
      "torch.Size([64, 1, 100])\n",
      "torch.Size([118, 1, 100])\n",
      "torch.Size([125, 1, 100])\n",
      "torch.Size([116, 1, 100])\n",
      "torch.Size([125, 1, 100])\n",
      "torch.Size([91, 1, 100])\n",
      "torch.Size([87, 1, 100])\n",
      "torch.Size([135, 1, 100])\n",
      "torch.Size([73, 1, 100])\n",
      "torch.Size([57, 1, 100])\n",
      "torch.Size([109, 1, 100])\n",
      "torch.Size([76, 1, 100])\n",
      "torch.Size([117, 1, 100])\n",
      "torch.Size([94, 1, 100])\n",
      "torch.Size([50, 1, 100])\n",
      "torch.Size([155, 1, 100])\n",
      "torch.Size([126, 1, 100])\n",
      "torch.Size([142, 1, 100])\n",
      "torch.Size([63, 1, 100])\n",
      "torch.Size([84, 1, 100])\n",
      "torch.Size([69, 1, 100])\n",
      "torch.Size([78, 1, 100])\n",
      "torch.Size([97, 1, 100])\n",
      "torch.Size([53, 1, 100])\n",
      "torch.Size([75, 1, 100])\n",
      "torch.Size([107, 1, 100])\n",
      "torch.Size([102, 1, 100])\n",
      "torch.Size([106, 1, 100])\n",
      "torch.Size([138, 1, 100])\n",
      "torch.Size([75, 1, 100])\n",
      "torch.Size([114, 1, 100])\n",
      "torch.Size([123, 1, 100])\n",
      "torch.Size([61, 1, 100])\n",
      "torch.Size([155, 1, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 595/40014 [00:01<02:07, 308.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([84, 1, 100])\n",
      "torch.Size([82, 1, 100])\n",
      "torch.Size([119, 1, 100])\n",
      "torch.Size([104, 1, 100])\n",
      "torch.Size([102, 1, 100])\n",
      "torch.Size([59, 1, 100])\n",
      "torch.Size([73, 1, 100])\n",
      "torch.Size([136, 1, 100])\n",
      "torch.Size([81, 1, 100])\n",
      "torch.Size([97, 1, 100])\n",
      "torch.Size([111, 1, 100])\n",
      "torch.Size([112, 1, 100])\n",
      "torch.Size([95, 1, 100])\n",
      "torch.Size([76, 1, 100])\n",
      "torch.Size([88, 1, 100])\n",
      "torch.Size([119, 1, 100])\n",
      "torch.Size([59, 1, 100])\n",
      "torch.Size([145, 1, 100])\n",
      "torch.Size([60, 1, 100])\n",
      "torch.Size([99, 1, 100])\n",
      "torch.Size([88, 1, 100])\n",
      "torch.Size([107, 1, 100])\n",
      "torch.Size([144, 1, 100])\n",
      "torch.Size([90, 1, 100])\n",
      "torch.Size([81, 1, 100])\n",
      "torch.Size([142, 1, 100])\n",
      "torch.Size([87, 1, 100])\n",
      "torch.Size([45, 1, 100])\n",
      "torch.Size([62, 1, 100])\n",
      "torch.Size([72, 1, 100])\n",
      "torch.Size([153, 1, 100])\n",
      "torch.Size([100, 1, 100])\n",
      "torch.Size([33, 1, 100])\n",
      "torch.Size([55, 1, 100])\n",
      "torch.Size([124, 1, 100])\n",
      "torch.Size([86, 1, 100])\n",
      "torch.Size([84, 1, 100])\n",
      "torch.Size([56, 1, 100])\n",
      "torch.Size([92, 1, 100])\n",
      "torch.Size([76, 1, 100])\n",
      "torch.Size([45, 1, 100])\n",
      "torch.Size([82, 1, 100])\n",
      "torch.Size([103, 1, 100])\n",
      "torch.Size([59, 1, 100])\n",
      "torch.Size([127, 1, 100])\n",
      "torch.Size([84, 1, 100])\n",
      "torch.Size([92, 1, 100])\n",
      "torch.Size([78, 1, 100])\n",
      "torch.Size([109, 1, 100])\n",
      "torch.Size([100, 1, 100])\n",
      "torch.Size([74, 1, 100])\n",
      "torch.Size([156, 1, 100])\n",
      "torch.Size([84, 1, 100])\n",
      "torch.Size([138, 1, 100])\n",
      "torch.Size([49, 1, 100])\n",
      "torch.Size([98, 1, 100])\n",
      "torch.Size([118, 1, 100])\n",
      "torch.Size([133, 1, 100])\n",
      "torch.Size([128, 1, 100])\n",
      "torch.Size([106, 1, 100])\n",
      "torch.Size([119, 1, 100])\n",
      "torch.Size([103, 1, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 663/40014 [00:02<02:10, 300.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([73, 1, 100])\n",
      "torch.Size([76, 1, 100])\n",
      "torch.Size([96, 1, 100])\n",
      "torch.Size([76, 1, 100])\n",
      "torch.Size([136, 1, 100])\n",
      "torch.Size([122, 1, 100])\n",
      "torch.Size([63, 1, 100])\n",
      "torch.Size([140, 1, 100])\n",
      "torch.Size([122, 1, 100])\n",
      "torch.Size([137, 1, 100])\n",
      "torch.Size([107, 1, 100])\n",
      "torch.Size([158, 1, 100])\n",
      "torch.Size([58, 1, 100])\n",
      "torch.Size([65, 1, 100])\n",
      "torch.Size([91, 1, 100])\n",
      "torch.Size([134, 1, 100])\n",
      "torch.Size([109, 1, 100])\n",
      "torch.Size([58, 1, 100])\n",
      "torch.Size([128, 1, 100])\n",
      "torch.Size([96, 1, 100])\n",
      "torch.Size([66, 1, 100])\n",
      "torch.Size([88, 1, 100])\n",
      "torch.Size([116, 1, 100])\n",
      "torch.Size([113, 1, 100])\n",
      "torch.Size([132, 1, 100])\n",
      "torch.Size([128, 1, 100])\n",
      "torch.Size([95, 1, 100])\n",
      "torch.Size([81, 1, 100])\n",
      "torch.Size([104, 1, 100])\n",
      "torch.Size([132, 1, 100])\n",
      "torch.Size([131, 1, 100])\n",
      "torch.Size([101, 1, 100])\n",
      "torch.Size([159, 1, 100])\n",
      "torch.Size([69, 1, 100])\n",
      "torch.Size([138, 1, 100])\n",
      "torch.Size([79, 1, 100])\n",
      "torch.Size([129, 1, 100])\n",
      "torch.Size([71, 1, 100])\n",
      "torch.Size([90, 1, 100])\n",
      "torch.Size([71, 1, 100])\n",
      "torch.Size([69, 1, 100])\n",
      "torch.Size([91, 1, 100])\n",
      "torch.Size([115, 1, 100])\n",
      "torch.Size([126, 1, 100])\n",
      "torch.Size([135, 1, 100])\n",
      "torch.Size([58, 1, 100])\n",
      "torch.Size([122, 1, 100])\n",
      "torch.Size([86, 1, 100])\n",
      "torch.Size([74, 1, 100])\n",
      "torch.Size([68, 1, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/patryk/Studia/PracaMagisterska/master-thesis/seq2seq/test_capacity_control.ipynb Cell 17'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/patryk/Studia/PracaMagisterska/master-thesis/seq2seq/test_capacity_control.ipynb#ch0000016?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m CREATE_DATASET:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/patryk/Studia/PracaMagisterska/master-thesis/seq2seq/test_capacity_control.ipynb#ch0000016?line=1'>2</a>\u001b[0m     train_latents \u001b[39m=\u001b[39m prepare_train_rows(dataset)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/patryk/Studia/PracaMagisterska/master-thesis/seq2seq/test_capacity_control.ipynb#ch0000016?line=2'>3</a>\u001b[0m     prepare_test_data(dataset)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/patryk/Studia/PracaMagisterska/master-thesis/seq2seq/test_capacity_control.ipynb#ch0000016?line=3'>4</a>\u001b[0m     test_latents \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mtest_dataset\u001b[39m.\u001b[39mprogress_apply(prepare_test_row, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32m/home/patryk/Studia/PracaMagisterska/master-thesis/seq2seq/test_capacity_control.ipynb Cell 16'\u001b[0m in \u001b[0;36mprepare_train_rows\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/patryk/Studia/PracaMagisterska/master-thesis/seq2seq/test_capacity_control.ipynb#ch0000015?line=20'>21</a>\u001b[0m     input_lengths \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39mlen\u001b[39m(input_tensor))\u001b[39m.\u001b[39munsqueeze(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/patryk/Studia/PracaMagisterska/master-thesis/seq2seq/test_capacity_control.ipynb#ch0000015?line=21'>22</a>\u001b[0m     \u001b[39mprint\u001b[39m(input_tensor\u001b[39m.\u001b[39munsqueeze(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/patryk/Studia/PracaMagisterska/master-thesis/seq2seq/test_capacity_control.ipynb#ch0000015?line=22'>23</a>\u001b[0m     mu, var, outputs, (hn, cn) \u001b[39m=\u001b[39m candidate_vae\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/patryk/Studia/PracaMagisterska/master-thesis/seq2seq/test_capacity_control.ipynb#ch0000015?line=23'>24</a>\u001b[0m         input_tensor\u001b[39m.\u001b[39;49munsqueeze(dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mto(DEVICE), input_lengths\u001b[39m.\u001b[39;49mto(\u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/patryk/Studia/PracaMagisterska/master-thesis/seq2seq/test_capacity_control.ipynb#ch0000015?line=24'>25</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/patryk/Studia/PracaMagisterska/master-thesis/seq2seq/test_capacity_control.ipynb#ch0000015?line=25'>26</a>\u001b[0m     z \u001b[39m=\u001b[39m candidate_vae\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mreparameterize(mu, var)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/patryk/Studia/PracaMagisterska/master-thesis/seq2seq/test_capacity_control.ipynb#ch0000015?line=27'>28</a>\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m disentangled_targets:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Studia/PracaMagisterska/master-thesis/seq2seq/model/encoder.py:162\u001b[0m, in \u001b[0;36mCandidateEncoder.forward\u001b[0;34m(self, input_tensor, input_lengths)\u001b[0m\n\u001b[1;32m    <a href='file:///home/patryk/Studia/PracaMagisterska/master-thesis/seq2seq/model/encoder.py?line=157'>158</a>\u001b[0m     input_tensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(input_tensor[:, :, \u001b[39m0\u001b[39m])\n\u001b[1;32m    <a href='file:///home/patryk/Studia/PracaMagisterska/master-thesis/seq2seq/model/encoder.py?line=159'>160</a>\u001b[0m input_tensor \u001b[39m=\u001b[39m pack_padded_sequence(input_tensor, input_lengths)\n\u001b[0;32m--> <a href='file:///home/patryk/Studia/PracaMagisterska/master-thesis/seq2seq/model/encoder.py?line=161'>162</a>\u001b[0m output, (hn, cn) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(input_tensor)\n\u001b[1;32m    <a href='file:///home/patryk/Studia/PracaMagisterska/master-thesis/seq2seq/model/encoder.py?line=163'>164</a>\u001b[0m output, _ \u001b[39m=\u001b[39m pad_packed_sequence(output)\n\u001b[1;32m    <a href='file:///home/patryk/Studia/PracaMagisterska/master-thesis/seq2seq/model/encoder.py?line=165'>166</a>\u001b[0m X \u001b[39m=\u001b[39m output[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :, :]\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py:764\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=760'>761</a>\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers,\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=761'>762</a>\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first)\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=762'>763</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=763'>764</a>\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, batch_sizes, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=764'>765</a>\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional)\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=765'>766</a>\u001b[0m output \u001b[39m=\u001b[39m result[\u001b[39m0\u001b[39m]\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=766'>767</a>\u001b[0m hidden \u001b[39m=\u001b[39m result[\u001b[39m1\u001b[39m:]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if CREATE_DATASET:\n",
    "    train_latents = prepare_train_rows(dataset)\n",
    "    prepare_test_data(dataset)\n",
    "    test_latents = dataset.test_dataset.progress_apply(prepare_test_row, axis=1)\n",
    "    os.makedirs(\"tests/data/capacity\", exist_ok=True)\n",
    "    with open(os.path.join(\"tests/data/capacity/train_latents.pickle\"), \"wb\") as f:\n",
    "        pickle.dump(train_latents, f)\n",
    "\n",
    "    with open(os.path.join(\"tests/data/capacity/test_latents.pickle\"), \"wb\") as f:\n",
    "        pickle.dump(test_latents, f)\n",
    "else:\n",
    "    with open(os.path.join(\"tests/data/capacity/train_latents.pickle\"), \"rb\") as f:\n",
    "        train_latents = pickle.load(f)\n",
    "\n",
    "    with open(os.path.join(\"tests/data/capacity/test_latents.pickle\"), \"rb\") as f:\n",
    "        test_latents = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdversarialDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, latents: dict, key: str):\n",
    "        self.data = [row[key] for row in latents]\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self.data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "adversarial_datasets_train = {\n",
    "    target: AdversarialDataset(train_latents, target) for target in disentangled_targets\n",
    "}\n",
    "\n",
    "\n",
    "adversarial_datasets_test = {\n",
    "    target: AdversarialDataset(test_latents, target) for target in disentangled_targets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_train = {\n",
    "    target: DataLoader(\n",
    "        adversarial_datasets_train[target],\n",
    "        batch_size=4096,\n",
    "    )\n",
    "    for target in disentangled_targets\n",
    "}\n",
    "\n",
    "dataloaders_test = {\n",
    "    target: DataLoader(\n",
    "        adversarial_datasets_test[target],\n",
    "        batch_size=1024,\n",
    "    )\n",
    "    for target in disentangled_targets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 1, 48])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloaders_train[\"skills\"]))[1].shape\n",
    "# next(iter(dataloaders_test[\"languages\"]))[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train / test methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(\n",
    "    model: nn.Module,\n",
    "    loss_fn: torch.nn.CrossEntropyLoss,\n",
    "    dataloader: DataLoader,\n",
    "    _type: str = \"mult\",\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    loss = 0\n",
    "    # _all = 0\n",
    "    iters = 0\n",
    "    for X_mult_batch, X_adv_batch, y_batch in dataloader:\n",
    "\n",
    "        y_pred = model(\n",
    "            X_mult_batch.squeeze(dim=1).cuda()\n",
    "            if _type == \"mult\"\n",
    "            else X_adv_batch.squeeze(dim=1).cuda()\n",
    "        )\n",
    "        iters += 1\n",
    "        loss += loss_fn(y_pred, y_batch.cuda())\n",
    "    return loss / iters\n",
    "\n",
    "\n",
    "def fit(\n",
    "    model: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    loss_fn: nn.CrossEntropyLoss,\n",
    "    train_dl: DataLoader,\n",
    "    val_dl: DataLoader,\n",
    "    writer: SummaryWriter,\n",
    "    epochs: int = 20,\n",
    "    print_metrics: bool = True,\n",
    "    patience: int = 5,\n",
    "    run_prefix: str = \"early_stopping\",\n",
    "    _type: str = \"mult\",\n",
    ") -> dict[str, list]:\n",
    "    losses = {\"train\": [], \"val\": []}\n",
    "\n",
    "    min_val_loss = 1e10\n",
    "    current_patience = 0\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "\n",
    "        for X_mult_batch, X_adv_batch, y_batch in train_dl:\n",
    "            X_batch = X_mult_batch if _type == \"mult\" else X_adv_batch\n",
    "            X_batch, y_batch = (\n",
    "                X_batch.squeeze(dim=1).cuda(),\n",
    "                y_batch.cuda(),\n",
    "            )\n",
    "            y_pred = model(\n",
    "                X_batch\n",
    "            )  # Uzyskanie pseudoprawdopodobieństw dla próbek z minibatcha\n",
    "\n",
    "            loss = loss_fn(y_pred, y_batch)  # Policzenie funkcji straty\n",
    "            loss.backward()  # Wsteczna propagacja z wyniku funkcji straty - policzenie gradientów i zapisanie ich w tensorach (parametrach)\n",
    "            optimizer.step()  # Aktualizacja parametrów modelu przez optymalizator na podstawie gradientów zapisanych w tensorach (parametrach) oraz lr\n",
    "            optimizer.zero_grad()  # Wyzerowanie gradientów w modelu, alternatywnie można wywołać model.zero_grad()\n",
    "\n",
    "        model.eval()  # Przełączenie na tryb ewaluacji modelu - istotne dla takich warstw jak Dropuot czy BatchNorm\n",
    "        with torch.no_grad():  # Wstrzymujemy przeliczanie i śledzenie gradientów dla tensorów - w procesie ewaluacji modelu nie chcemy zmian w gradientach\n",
    "            train_loss = validate(model, loss_fn, train_dl, _type)\n",
    "            val_loss = validate(model, loss_fn, val_dl, _type)\n",
    "\n",
    "            if val_loss < min_val_loss:\n",
    "                min_val_loss = val_loss\n",
    "                current_patience = 0\n",
    "                os.makedirs(\"tests/checkpoints/capacity\", exist_ok=True)\n",
    "                torch.save(\n",
    "                    obj={\n",
    "                        \"epoch\": epoch,\n",
    "                        \"model_state_dict\": model.state_dict(),\n",
    "                        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    },\n",
    "                    f=\"tests/checkpoints/capacity/best\" + \"_\" + run_prefix,\n",
    "                )\n",
    "            else:\n",
    "                current_patience += 1\n",
    "\n",
    "        losses[\"train\"].append(train_loss)\n",
    "        losses[\"val\"].append(val_loss)\n",
    "\n",
    "        writer.add_scalars(\n",
    "            main_tag=f\"{run_prefix}/loss\",\n",
    "            tag_scalar_dict={\"train\": train_loss, \"dev\": val_loss},\n",
    "            global_step=epoch + 1,\n",
    "        )\n",
    "\n",
    "        if print_metrics:\n",
    "            print(\n",
    "                f\"Epoch {epoch}: \"\n",
    "                f\"train loss = {train_loss:.3f}, \"\n",
    "                f\"validation loss = {val_loss:.3f}\"\n",
    "            )\n",
    "\n",
    "        if current_patience >= patience:\n",
    "            break\n",
    "\n",
    "    model.eval()  # Przełączenie na tryb ewaluacji modelu - istotne dla takich warstw jak Dropuot czy BatchNorm\n",
    "    # return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define networks to be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossentropy_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "multitask_classifiers = nn.ModuleDict(\n",
    "    {\n",
    "        target: nn.Linear(\n",
    "            disentangled_targets[target][\"latent_dim\"],\n",
    "            disentangled_targets[target][\"output_dim\"],\n",
    "        ).to(DEVICE)\n",
    "        for target in disentangled_targets\n",
    "    }\n",
    ")\n",
    "# Retreiving target using all except target. Classifiers should fail :)\n",
    "adversarial_classifiers = nn.ModuleDict(\n",
    "    {\n",
    "        target: nn.Linear(\n",
    "            general_config.latent_dim - disentangled_targets[target][\"latent_dim\"],\n",
    "            disentangled_targets[target][\"output_dim\"],\n",
    "        ).to(DEVICE)\n",
    "        for target in disentangled_targets\n",
    "    }\n",
    ")\n",
    "\n",
    "multitask_optimizers = {\n",
    "    target: torch.optim.Adam(\n",
    "        multitask_classifiers[target].parameters(),\n",
    "        lr=0.05,\n",
    "    )\n",
    "    for target in disentangled_targets\n",
    "}\n",
    "\n",
    "adversarial_optimizers = {\n",
    "    target: torch.optim.Adam(\n",
    "        adversarial_classifiers[target].parameters(),\n",
    "        lr=0.05,\n",
    "    )\n",
    "    for target in disentangled_targets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [01:55<00:28,  1.45s/it]\n",
      " 50%|█████     | 50/100 [01:18<01:18,  1.56s/it]\n",
      " 23%|██▎       | 23/100 [00:39<02:13,  1.73s/it]\n",
      " 23%|██▎       | 23/100 [00:38<02:10,  1.69s/it]\n",
      " 82%|████████▏ | 82/100 [00:16<00:03,  4.88it/s]\n",
      " 46%|████▌     | 46/100 [00:09<00:11,  4.73it/s]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "\n",
    "for target in disentangled_targets:\n",
    "    _type = \"mult\"\n",
    "    fit(\n",
    "        model=multitask_classifiers[target],\n",
    "        optimizer=multitask_optimizers[target],\n",
    "        loss_fn=crossentropy_loss,\n",
    "        train_dl=dataloaders_train[target],\n",
    "        val_dl=dataloaders_test[target],\n",
    "        writer=writer_tensorboard,\n",
    "        epochs=EPOCHS,\n",
    "        print_metrics=False,\n",
    "        patience=10,\n",
    "        run_prefix=f\"capacity_{_type}_{target}_{EXPERIMENT}_{CHECKPOINT.replace('.tar', '')}\",\n",
    "        _type=_type,\n",
    "    )\n",
    "    _type = \"adv\"\n",
    "    fit(\n",
    "        model=adversarial_classifiers[target],\n",
    "        optimizer=adversarial_optimizers[target],\n",
    "        loss_fn=crossentropy_loss,\n",
    "        train_dl=dataloaders_train[target],\n",
    "        val_dl=dataloaders_test[target],\n",
    "        writer=writer_tensorboard,\n",
    "        epochs=EPOCHS,\n",
    "        print_metrics=False,\n",
    "        patience=10,\n",
    "        run_prefix=f\"capacity_{_type}_{target}_{EXPERIMENT}_{CHECKPOINT.replace('.tar', '')}\",\n",
    "        _type=_type,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a62dc5c4e15874d230a4f396bb129d37f109e576af212db1e92385126337577"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
