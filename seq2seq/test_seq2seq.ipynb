{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First attempt to create a new representation method for a candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-05-22 20:06:42,841] {utils.py:147} INFO - Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "[2022-05-22 20:06:42,842] {utils.py:159} INFO - NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from model.encoder import CandidateEncoderConfig\n",
    "from model.decoder import CandidateDecoderConfig\n",
    "from model.candidate_vae import CandidateVAE\n",
    "from trainer.trainer import BetaVaeTrainer, TrainerConfig\n",
    "from config.general_config import GeneralConfig\n",
    "from model.embedder import EmbedderType\n",
    "from dataset.utils import pad_collate\n",
    "from dataset.dataset import SellersDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "with open(\"config/config.yaml\", \"r\") as file:\n",
    "    try:\n",
    "        config = yaml.safe_load(file)[\"vae\"]\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "general_config = GeneralConfig(**config[\"general\"])\n",
    "encoder_config = CandidateEncoderConfig(**config[\"encoder\"], **config[\"general\"])\n",
    "\n",
    "decoder_config = CandidateDecoderConfig(**config[\"decoder\"], **config[\"general\"])\n",
    "\n",
    "trainer_config = TrainerConfig(**config[\"trainer\"], **config[\"general\"])\n",
    "\n",
    "log_dir = os.path.join(general_config.checkpoints_dir, \"runs\")\n",
    "\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "writer_tensorboard = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 63659), started 0:59:22 ago. (Use '!kill 63659' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-50b34f2773f688a8\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-50b34f2773f688a8\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir $log_dir --port=6008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset\n",
      "[2022-05-22 20:06:43,490] {dataset.py:142} INFO - Preparing dataset\n",
      "Detecting languages:\n",
      "[2022-05-22 20:06:43,491] {dataset.py:169} INFO - Detecting languages:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 13.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected languages:\n",
      "[2022-05-22 20:06:43,793] {dataset.py:174} INFO - Detected languages:\n",
      "lang\n",
      "en    4\n",
      "Name: lang, dtype: int64\n",
      "[2022-05-22 20:06:43,794] {dataset.py:175} INFO - lang\n",
      "en    4\n",
      "Name: lang, dtype: int64\n",
      "Removing rows not written in english\n",
      "[2022-05-22 20:06:43,795] {dataset.py:176} INFO - Removing rows not written in english\n",
      "Removed 0 rows\n",
      "[2022-05-22 20:06:43,796] {dataset.py:180} INFO - Removed 0 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 4416.22it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 4499.12it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 1346.16it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 9034.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding language for languages_str\n",
      "[2022-05-22 20:06:43,809] {dataset.py:356} INFO - Adding language for languages_str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 14563.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding language for education_str\n",
      "[2022-05-22 20:06:43,811] {dataset.py:356} INFO - Adding language for education_str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 16304.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding language for skills_str\n",
      "[2022-05-22 20:06:43,812] {dataset.py:356} INFO - Adding language for skills_str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 8309.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding language for description_str\n",
      "[2022-05-22 20:06:43,815] {dataset.py:356} INFO - Adding language for description_str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 7250.31it/s]\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "dataset = SellersDataset(\n",
    "    embedder_name=config[\"general\"][\"embedder_name\"],\n",
    "    data_path=config[\"general\"][\"data_path\"],\n",
    "    device=DEVICE,\n",
    ")\n",
    "dataset.prepare_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=general_config.batch_size,\n",
    "    collate_fn=pad_collate(dataset.vocab.pad_token),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models to test them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_vae = CandidateVAE(\n",
    "    general_config, encoder_config, decoder_config, dataset.vocab, dataset.embedder\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check encoder / decoder separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/patryk/TOSHIBA EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/dataset/dataset.py:338: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row[\"skills_str\"] = (\n"
     ]
    }
   ],
   "source": [
    "input_pad, input_lengths, target_pad, mask, max_target_length = next(iter(dataloader))\n",
    "\n",
    "input_pad = input_pad.to(DEVICE)\n",
    "target_pad = target_pad.to(DEVICE)\n",
    "input_lengths = input_lengths.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, var, outputs, (hn, cn) = candidate_vae.encoder(input_pad, input_lengths)\n",
    "mu.shape, var.shape, outputs.shape\n",
    "\n",
    "latent_vector = candidate_vae.decoder.reparameterize(mu, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_hidden = candidate_vae.decoder.init_hidden_cell(general_config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden, attn_weights, attn_mu, attn_var = candidate_vae.decoder(\n",
    "    latent_vector, init_hidden, outputs, True\n",
    ")\n",
    "output = torch.argmax(output, dim=1).view(-1, 1)\n",
    "if general_config.embedder_name != EmbedderType.LANG:\n",
    "    output = candidate_vae.embed_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 220])\n"
     ]
    }
   ],
   "source": [
    "output, hidden, attn_weights, attn_mu, attn_var = candidate_vae.decoder(\n",
    "    output, hidden, outputs, False\n",
    ")\n",
    "print(output.shape)\n",
    "output = torch.argmax(output, dim=1).view(-1, 1)\n",
    "if general_config.embedder_name != EmbedderType.LANG:\n",
    "    output = candidate_vae.embed_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden, attn_weights, attn_mu, attn_var = candidate_vae.decoder(\n",
    "    output, hidden, outputs, False\n",
    ")\n",
    "output = torch.argmax(output, dim=1).view(-1, 1)\n",
    "if general_config.embedder_name != EmbedderType.LANG:\n",
    "    output = candidate_vae.embed_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check all together for batched input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pad, input_lengths, target_pad, mask, max_target_length = next(iter(dataloader))\n",
    "\n",
    "input_pad = input_pad.to(DEVICE)\n",
    "target_pad = target_pad.to(DEVICE)\n",
    "input_lengths = input_lengths.to(\"cpu\")\n",
    "\n",
    "outputs, attentions = candidate_vae.forward(input_pad, input_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BetaVaeTrainer...\n",
      "[2022-05-22 20:07:10,590] {trainer.py:163} INFO - Initializing BetaVaeTrainer...\n",
      "Done: BetaVaeTrainer initialized!\n",
      "[2022-05-22 20:07:10,591] {trainer.py:193} INFO - Done: BetaVaeTrainer initialized!\n"
     ]
    }
   ],
   "source": [
    "encoder_optimizer = torch.optim.Adam(\n",
    "    candidate_vae.encoder.parameters(), lr=general_config.encoder_lr\n",
    ")\n",
    "decoder_optimizer = torch.optim.Adam(\n",
    "    candidate_vae.decoder.parameters(), lr=general_config.decoder_lr\n",
    ")\n",
    "\n",
    "trainer = BetaVaeTrainer(\n",
    "    candidate_vae,\n",
    "    encoder_optimizer,\n",
    "    decoder_optimizer,\n",
    "    general_config,\n",
    "    trainer_config,\n",
    "    dataloader,\n",
    "    writer_tensorboard,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 0/128\n",
      "[2022-05-22 20:07:13,360] {trainer.py:426} INFO - Epoch 0/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:58<00:00, 29.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "[2022-05-22 20:08:12,107] {trainer.py:426} INFO - Epoch 1/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:57<00:00, 28.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/128\n",
      "[2022-05-22 20:09:09,884] {trainer.py:426} INFO - Epoch 2/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:57<00:00, 28.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/128\n",
      "[2022-05-22 20:10:06,992] {trainer.py:426} INFO - Epoch 3/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:57<00:00, 28.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/128\n",
      "[2022-05-22 20:11:04,798] {trainer.py:426} INFO - Epoch 4/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:57<00:00, 28.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/128\n",
      "[2022-05-22 20:12:02,425] {trainer.py:426} INFO - Epoch 5/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:57<00:00, 28.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/128\n",
      "[2022-05-22 20:12:59,915] {trainer.py:426} INFO - Epoch 6/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:57<00:00, 28.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/128\n",
      "[2022-05-22 20:13:57,535] {trainer.py:426} INFO - Epoch 7/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:58<00:00, 29.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/128\n",
      "[2022-05-22 20:14:55,650] {trainer.py:426} INFO - Epoch 8/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:58<00:00, 29.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/128\n",
      "[2022-05-22 20:15:54,313] {trainer.py:426} INFO - Epoch 9/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:57<00:00, 28.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/128\n",
      "[2022-05-22 20:16:52,270] {trainer.py:426} INFO - Epoch 10/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:51<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/media/patryk/TOSHIBA EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/test_seq2seq.ipynb Cell 25'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/test_seq2seq.ipynb#ch0000023?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit()\n",
      "File \u001b[0;32m/media/patryk/TOSHIBA EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py:439\u001b[0m, in \u001b[0;36mBetaVaeTrainer.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=435'>436</a>\u001b[0m mask \u001b[39m=\u001b[39m mask\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvae\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=436'>437</a>\u001b[0m input_lengths \u001b[39m=\u001b[39m input_lengths\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=438'>439</a>\u001b[0m loss, recons_loss, kld_loss, kld_attn_loss, beta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step(\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=439'>440</a>\u001b[0m     input_pad,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=440'>441</a>\u001b[0m     input_lengths,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=441'>442</a>\u001b[0m     target_pad,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=442'>443</a>\u001b[0m     mask,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=443'>444</a>\u001b[0m     max_target_length,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=444'>445</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=445'>446</a>\u001b[0m logging_losses[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=446'>447</a>\u001b[0m logging_losses[\u001b[39m\"\u001b[39m\u001b[39mrecons_loss\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m recons_loss\n",
      "File \u001b[0;32m/media/patryk/TOSHIBA EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py:386\u001b[0m, in \u001b[0;36mBetaVaeTrainer.train_step\u001b[0;34m(self, input_tensor, input_lengths, target_tensor, mask, max_target_length)\u001b[0m\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=383'>384</a>\u001b[0m     kld_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_kld_loss\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=384'>385</a>\u001b[0m     kld_attn_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_kld_attn_loss\n\u001b[0;32m--> <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=385'>386</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=387'>388</a>\u001b[0m \u001b[39m# Clip gradients: gradients are modified in place\u001b[39;00m\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=388'>389</a>\u001b[0m _ \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvae\u001b[39m.\u001b[39mencoder\u001b[39m.\u001b[39mparameters(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mclip)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a62dc5c4e15874d230a4f396bb129d37f109e576af212db1e92385126337577"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
