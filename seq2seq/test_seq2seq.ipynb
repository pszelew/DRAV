{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First attempt to createÂ a new representation method for a candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from model.encoder import CandidateEncoderConfig\n",
    "from model.decoder import CandidateDecoderConfig\n",
    "from model.candidate_vae import CandidateVAE\n",
    "from trainer.trainer import BetaVaeTrainer, TrainerConfig\n",
    "from config.general_config import GeneralConfig\n",
    "from model.embedder import EmbedderType\n",
    "from dataset.utils import pad_collate\n",
    "from dataset.dataset import SellersDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'english basic im a passionate content writer i have written research articles for about eight years and this vast experience has shaped my research and writing profession i value quality work and i am driven by the need to offer the best and meet the clients needs some of the preferred areas of research include nursing public health psychology business marketing and economics bsc nursing nairobi university kenya graduated 2012 my skills are typewriting data entry microsoft word typing editing content writing'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset.utils import normalizeString\n",
    "\n",
    "normalizeString(\n",
    "    \"english basic im a passionate content writer i have written research articles for about eight years and this vast experience has shaped my research and writing profession i value quality work and i am driven by the need to offer the best and meet the clients' needs some of the preferred areas of research include nursing public health psychology business marketing and economics bsc nursing nairobi university kenya graduated 2012 my skills are typewriting data entry microsoft word typing editing content writing\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.vocab.word2index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "with open(\"config/config.yaml\", \"r\") as file:\n",
    "    try:\n",
    "        config = yaml.safe_load(file)[\"vae\"]\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "general_config = GeneralConfig(**config[\"general\"])\n",
    "encoder_config = CandidateEncoderConfig(**config[\"encoder\"], **config[\"general\"])\n",
    "\n",
    "decoder_config = CandidateDecoderConfig(**config[\"decoder\"], **config[\"general\"])\n",
    "\n",
    "trainer_config = TrainerConfig(**config[\"trainer\"], **config[\"general\"])\n",
    "\n",
    "log_dir = os.path.join(general_config.checkpoints_dir, \"runs\")\n",
    "\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "writer_tensorboard = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reload_ext tensorboard\n",
    "# %tensorboard --logdir $log_dir --port=6008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset data/dataset/...\n",
      "[2022-05-30 01:18:27,045] {dataset.py:226} INFO - Loading dataset data/dataset/...\n",
      "Loaded dataset data/dataset/!\n",
      "[2022-05-30 01:18:27,358] {dataset.py:245} INFO - Loaded dataset data/dataset/!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "dataset = SellersDataset(\n",
    "    dataset_path=general_config.datset_path,\n",
    "    embedder_name=general_config.embedder_name,\n",
    "    raw_data_path=general_config.raw_data_path,\n",
    "    device=DEVICE,\n",
    "    bow_remove_stopwords=general_config.bow_remove_stopwords,\n",
    "    bow_remove_sentiment=general_config.bow_remove_sentiment,\n",
    "    nn_embedding_size=encoder_config.lstm_hidden_dim,\n",
    "    trim_tr=general_config.trim_tr,\n",
    ")\n",
    "# dataset.prepare_dataset()\n",
    "dataset.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14419"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.bow_vocab.n_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=general_config.batch_size,\n",
    "    collate_fn=pad_collate(dataset.vocab.pad_token),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_vae = CandidateVAE(\n",
    "    general_config, encoder_config, decoder_config, dataset.vocab, dataset.embedder\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check encoder / decoder separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (\n",
    "#     input_pad,\n",
    "#     input_lengths,\n",
    "#     target_pad,\n",
    "#     mask,\n",
    "#     max_target_length,\n",
    "#     target_skills,\n",
    "#     target_education,\n",
    "#     target_languages,\n",
    "# ) = next(iter(dataloader))\n",
    "\n",
    "# input_pad = input_pad.to(DEVICE)\n",
    "# target_pad = target_pad.to(DEVICE)\n",
    "# input_lengths = input_lengths.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu, var, outputs, (hn, cn) = candidate_vae.encoder(input_pad, input_lengths)\n",
    "# mu.shape, var.shape, outputs.shape\n",
    "\n",
    "# latent_vector = candidate_vae.decoder.reparameterize(mu, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_hidden = candidate_vae.decoder.init_hidden_cell(latent_vector.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output, hidden, attn_weights, attn_mu, attn_var = candidate_vae.decoder(\n",
    "#     latent_vector, init_hidden, outputs, True\n",
    "# )\n",
    "# output = torch.argmax(output, dim=1).view(-1, 1)\n",
    "\n",
    "# if general_config.embedder_name != EmbedderType.LANG:\n",
    "#     output = candidate_vae.embed_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output, hidden, attn_weights, attn_mu, attn_var = candidate_vae.decoder(\n",
    "#     output, hidden, outputs, False\n",
    "# )\n",
    "\n",
    "# output = torch.argmax(output, dim=1).view(-1, 1)\n",
    "# if general_config.embedder_name != EmbedderType.LANG:\n",
    "#     output = candidate_vae.embed_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output, hidden, attn_weights, attn_mu, attn_var = candidate_vae.decoder(\n",
    "#     output, hidden, outputs, False\n",
    "# )\n",
    "# output = torch.argmax(output, dim=1).view(-1, 1)\n",
    "# if general_config.embedder_name != EmbedderType.LANG:\n",
    "#     output = candidate_vae.embed_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10# Check all together for batched input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (\n",
    "#     input_pad,\n",
    "#     input_lengths,\n",
    "#     target_pad,\n",
    "#     mask,\n",
    "#     max_target_length,\n",
    "#     target_skills,\n",
    "#     target_education,\n",
    "#     target_languages,\n",
    "# ) = next(iter(dataloader))\n",
    "\n",
    "# input_pad = input_pad.to(DEVICE)\n",
    "# target_pad = target_pad.to(DEVICE)\n",
    "# input_lengths = input_lengths.to(\"cpu\")\n",
    "\n",
    "# outputs, attentions = candidate_vae.forward(input_pad, input_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BetaVaeTrainer...\n",
      "[2022-05-30 01:18:29,765] {trainer.py:227} INFO - Initializing BetaVaeTrainer...\n",
      "Done: BetaVaeTrainer initialized!\n",
      "[2022-05-30 01:18:29,790] {trainer.py:339} INFO - Done: BetaVaeTrainer initialized!\n"
     ]
    }
   ],
   "source": [
    "trainer = BetaVaeTrainer(\n",
    "    candidate_vae,\n",
    "    general_config,\n",
    "    trainer_config,\n",
    "    dataloader,\n",
    "    writer_tensorboard,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loop...\n",
      "[2022-05-30 01:18:29,793] {trainer.py:690} INFO - Training loop...\n",
      "Epoch 0/20\n",
      "[2022-05-30 01:18:29,794] {trainer.py:692} INFO - Epoch 0/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|âââââââââââââââââââââââââââââââââââââââ| 4101/4101 [45:54<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "[2022-05-30 02:04:24,284] {trainer.py:692} INFO - Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|âââââââââââââââââââââââââââââââââââââââ| 4101/4101 [45:09<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "[2022-05-30 02:49:33,845] {trainer.py:692} INFO - Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|âââââââââââââââââââââââââââââââââââââââ| 4101/4101 [45:02<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "[2022-05-30 03:34:36,655] {trainer.py:692} INFO - Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|âââââââââââââââââââââââââââââââââââââââ| 4101/4101 [45:04<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "[2022-05-30 04:19:40,780] {trainer.py:692} INFO - Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|âââââââââââââââââââââââââââââââââââââââ| 4101/4101 [45:05<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "[2022-05-30 05:04:46,048] {trainer.py:692} INFO - Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|âââââââââââââââââââââââââââââââââââââââ| 4101/4101 [45:07<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "[2022-05-30 05:49:53,196] {trainer.py:692} INFO - Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|âââââââââââââââââââââââââââââââââââââââ| 4101/4101 [45:06<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "[2022-05-30 06:34:59,997] {trainer.py:692} INFO - Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|âââââââââââââââââââââââââââââââââââââââ| 4101/4101 [44:59<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "[2022-05-30 07:19:59,783] {trainer.py:692} INFO - Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|âââââââââââââââââââââââââââââââââââââââ| 4101/4101 [45:16<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "[2022-05-30 08:05:15,867] {trainer.py:692} INFO - Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|ââââââââââ                              | 944/4101 [11:05<35:32,  1.48it/s]"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a62dc5c4e15874d230a4f396bb129d37f109e576af212db1e92385126337577"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
