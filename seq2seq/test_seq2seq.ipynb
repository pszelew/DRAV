{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First attempt to create a new representation method for a candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pad_packed_sequence\n",
    "import pandas as pd\n",
    "\n",
    "from model.encoder import CandidateEncoder, CandidateEncoderConfig\n",
    "from model.decoder import CandidateDecoder, CandidateDecoderConfig\n",
    "from config.general_config import GeneralConfig\n",
    "from model.embedder import EmbedderType\n",
    "from dataset.utils import pad_collate\n",
    "from dataset.dataset import SellersDataset\n",
    "from dataset.language import Lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "with open(\"config/config.yaml\", \"r\") as file:\n",
    "    try:\n",
    "        config = yaml.safe_load(file)[\"vae\"]\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "GENERAL_CONFIG = GeneralConfig(**config[\"general\"], device = DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-05-20 09:44:30,458] {dataset.py:133} INFO - Preparing dataset\n",
      "[2022-05-20 09:44:30,458] {dataset.py:160} INFO - Detecting languages:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 14.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-05-20 09:44:30,738] {dataset.py:165} INFO - Detected languages:\n",
      "[2022-05-20 09:44:30,739] {dataset.py:166} INFO - lang\n",
      "en    4\n",
      "Name: lang, dtype: int64\n",
      "[2022-05-20 09:44:30,740] {dataset.py:167} INFO - Removing rows not written in english\n",
      "[2022-05-20 09:44:30,741] {dataset.py:171} INFO - Removed 0 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 5173.36it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 5270.88it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 1346.70it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11044.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-05-20 09:44:30,752] {dataset.py:347} INFO - Adding language for languages_str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 20997.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-05-20 09:44:30,754] {dataset.py:347} INFO - Adding language for education_str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 21760.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-05-20 09:44:30,755] {dataset.py:347} INFO - Adding language for skills_str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 16178.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-05-20 09:44:30,757] {dataset.py:347} INFO - Adding language for description_str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 7476.48it/s]\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "dataset = SellersDataset(\n",
    "    embedder_name=config[\"general\"][\"embedder_name\"], data_path=config[\"general\"][\"data_path\"], device=DEVICE\n",
    ")\n",
    "dataset.prepare_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=GENERAL_CONFIG.batch_size, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_encoder = CandidateEncoderConfig(\n",
    "    num_words=dataset.lang.n_words,\n",
    "    embedding_size=dataset.embedder.size,\n",
    "    device=DEVICE,\n",
    "    **config[\"encoder\"],\n",
    "    **config[\"general\"]\n",
    ")\n",
    "\n",
    "encoder = CandidateEncoder(config_encoder).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/patryk/TOSHIBA EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/dataset/dataset.py:329: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row[\"skills_str\"] = (\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 16]), torch.Size([3, 16]), torch.Size([3, 202, 128]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu, var, outputs, (hn, cn) = encoder(next(iter(loader)).cuda())\n",
    "mu.shape, var.shape, outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparameterize(mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Will a single z be enough ti compute the expectation\n",
    "    for the loss??\n",
    "    :param mu: (Tensor) Mean of the latent Gaussian\n",
    "    :param logvar: (Tensor) Standard deviation of the latent Gaussian\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return eps * std + mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 16])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_vector = reparameterize(mu, var)\n",
    "latent_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_decoder = CandidateDecoderConfig(\n",
    "    num_words=dataset.lang.n_words,\n",
    "    embedding_size=dataset.embedder.size,\n",
    "    device=DEVICE,\n",
    "    **config[\"decoder\"],\n",
    "    **config[\"general\"]\n",
    ")\n",
    "\n",
    "decoder = CandidateDecoder(config_decoder).to(DEVICE)\n",
    "\n",
    "init_hidden = decoder.init_hidden_cell(GENERAL_CONFIG.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_strip_sequence(batch):\n",
    "    template = torch.zeros(GENERAL_CONFIG.max_seq_len, batch.shape[-1], device=DEVICE)\n",
    "    return pad_sequence([template, *batch], batch_first=True)[1:,:GENERAL_CONFIG.max_seq_len,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_strip_sequence(outputs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_output(output: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Create embedding of the output of decoder\n",
    "\n",
    "    output : torch.Tensor\n",
    "        Tensor of shape [N, 1] where:\n",
    "        - N is the output of the decoder\n",
    "    \"\"\"\n",
    "    \n",
    "    return torch.stack([dataset.embedder(dataset.lang.index2word[int(word)], pooled=True).squeeze(dim=0) for word in output], dim=0).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "torch.Size([3, 64])\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "output, hidden, attn_weights = decoder(latent_vector, init_hidden, pad_strip_sequence(outputs), True)\n",
    "output = torch.argmax(output, dim=1).view(-1, 1)\n",
    "if GENERAL_CONFIG.embedder_name != EmbedderType.LANG:\n",
    "    output = embed_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "torch.Size([3, 64])\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "output, hidden, attn_weights = decoder(output, hidden, pad_strip_sequence(outputs), False)\n",
    "output = torch.argmax(output, dim=1).view(-1, 1)\n",
    "if GENERAL_CONFIG.embedder_name != EmbedderType.LANG:\n",
    "    output = embed_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "torch.Size([3, 64])\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "output, hidden, attn_weights = decoder(output, hidden, pad_strip_sequence(outputs), False)\n",
    "output = torch.argmax(output, dim=1).view(-1, 1)\n",
    "if GENERAL_CONFIG.embedder_name != EmbedderType.LANG:\n",
    "    output = embed_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a62dc5c4e15874d230a4f396bb129d37f109e576af212db1e92385126337577"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
