{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First attempt to create a new representation method for a candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-05-23 21:40:26,541] {utils.py:147} INFO - Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "[2022-05-23 21:40:26,542] {utils.py:159} INFO - NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from model.encoder import CandidateEncoderConfig\n",
    "from model.decoder import CandidateDecoderConfig\n",
    "from model.candidate_vae import CandidateVAE\n",
    "from trainer.trainer import BetaVaeTrainer, TrainerConfig\n",
    "from config.general_config import GeneralConfig\n",
    "from model.embedder import EmbedderType\n",
    "from dataset.utils import pad_collate\n",
    "from dataset.dataset import SellersDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "with open(\"config/config.yaml\", \"r\") as file:\n",
    "    try:\n",
    "        config = yaml.safe_load(file)[\"vae\"]\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "general_config = GeneralConfig(**config[\"general\"])\n",
    "encoder_config = CandidateEncoderConfig(**config[\"encoder\"], **config[\"general\"])\n",
    "\n",
    "decoder_config = CandidateDecoderConfig(**config[\"decoder\"], **config[\"general\"])\n",
    "\n",
    "trainer_config = TrainerConfig(**config[\"trainer\"], **config[\"general\"])\n",
    "\n",
    "log_dir = os.path.join(general_config.checkpoints_dir, \"runs\")\n",
    "\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "writer_tensorboard = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 63659), started 1 day, 2:33:05 ago. (Use '!kill 63659' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1d2ea5dd7b744705\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1d2ea5dd7b744705\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir $log_dir --port=6008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset\n",
      "[2022-05-23 21:40:27,376] {dataset.py:108} INFO - Preparing dataset\n",
      "Detecting languages:\n",
      "[2022-05-23 21:40:27,377] {dataset.py:150} INFO - Detecting languages:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 13.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected languages:\n",
      "[2022-05-23 21:40:27,678] {dataset.py:155} INFO - Detected languages:\n",
      "lang\n",
      "de    1\n",
      "en    3\n",
      "Name: lang, dtype: int64\n",
      "[2022-05-23 21:40:27,679] {dataset.py:156} INFO - lang\n",
      "de    1\n",
      "en    3\n",
      "Name: lang, dtype: int64\n",
      "Removing rows not written in english\n",
      "[2022-05-23 21:40:27,680] {dataset.py:157} INFO - Removing rows not written in english\n",
      "Removed 1 rows\n",
      "[2022-05-23 21:40:27,681] {dataset.py:161} INFO - Removed 1 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 6285.17it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10727.12it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 6982.75it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 8300.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding bow for languages_str\n",
      "[2022-05-23 21:40:27,689] {dataset.py:408} INFO - Adding bow for languages_str\n",
      "Adding bow for education_str\n",
      "[2022-05-23 21:40:27,689] {dataset.py:408} INFO - Adding bow for education_str\n",
      "Adding bow for skills_str\n",
      "[2022-05-23 21:40:27,690] {dataset.py:408} INFO - Adding bow for skills_str\n",
      "Adding bow for description_str\n",
      "[2022-05-23 21:40:27,690] {dataset.py:408} INFO - Adding bow for description_str\n",
      "Adding language for languages_str\n",
      "[2022-05-23 21:40:27,691] {dataset.py:399} INFO - Adding language for languages_str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 14496.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding language for education_str\n",
      "[2022-05-23 21:40:27,692] {dataset.py:399} INFO - Adding language for education_str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 9845.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding language for skills_str\n",
      "[2022-05-23 21:40:27,694] {dataset.py:399} INFO - Adding language for skills_str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 10736.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding language for description_str\n",
      "[2022-05-23 21:40:27,696] {dataset.py:399} INFO - Adding language for description_str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 7566.39it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 4158.27it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 5186.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping missing values...\n",
      "[2022-05-23 21:40:27,702] {dataset.py:132} INFO - Dropping missing values...\n",
      "Dropped 1 missing values...\n",
      "[2022-05-23 21:40:27,703] {dataset.py:137} INFO - Dropped 1 missing values...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "dataset = SellersDataset(\n",
    "    embedder_name=config[\"general\"][\"embedder_name\"],\n",
    "    data_path=config[\"general\"][\"data_path\"],\n",
    "    device=DEVICE,\n",
    "    bow_remove_stopwords=config[\"general\"][\"bow_remove_stopwords\"],\n",
    "    bow_remove_sentiment=config[\"general\"][\"bow_remove_sentiment\"],\n",
    ")\n",
    "dataset.prepare_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=general_config.batch_size,\n",
    "    collate_fn=pad_collate(dataset.vocab.pad_token),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models to test them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_vae = CandidateVAE(\n",
    "    general_config, encoder_config, decoder_config, dataset.vocab, dataset.embedder\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check encoder / decoder separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    input_pad,\n",
    "    input_lengths,\n",
    "    target_pad,\n",
    "    mask,\n",
    "    max_target_length,\n",
    "    target_skills,\n",
    "    target_education,\n",
    "    target_languages,\n",
    ") = next(iter(dataloader))\n",
    "\n",
    "input_pad = input_pad.to(DEVICE)\n",
    "target_pad = target_pad.to(DEVICE)\n",
    "input_lengths = input_lengths.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, var, outputs, (hn, cn) = candidate_vae.encoder(input_pad, input_lengths)\n",
    "mu.shape, var.shape, outputs.shape\n",
    "\n",
    "latent_vector = candidate_vae.decoder.reparameterize(mu, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_hidden = candidate_vae.decoder.init_hidden_cell(general_config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden[0] size (8, 2, 64), got [8, 3, 64]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/media/patryk/TOSHIBA EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/test_seq2seq.ipynb Cell 18'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/test_seq2seq.ipynb#ch0000017?line=0'>1</a>\u001b[0m output, hidden, attn_weights, attn_mu, attn_var \u001b[39m=\u001b[39m candidate_vae\u001b[39m.\u001b[39;49mdecoder(\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/test_seq2seq.ipynb#ch0000017?line=1'>2</a>\u001b[0m     latent_vector, init_hidden, outputs, \u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/test_seq2seq.ipynb#ch0000017?line=2'>3</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/test_seq2seq.ipynb#ch0000017?line=3'>4</a>\u001b[0m output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(output, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/test_seq2seq.ipynb#ch0000017?line=4'>5</a>\u001b[0m \u001b[39mif\u001b[39;00m general_config\u001b[39m.\u001b[39membedder_name \u001b[39m!=\u001b[39m EmbedderType\u001b[39m.\u001b[39mLANG:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/media/patryk/TOSHIBA EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/model/decoder.py:424\u001b[0m, in \u001b[0;36mCandidateDecoder.forward\u001b[0;34m(self, prev_token, prev_hidden, encoder_outputs, feed_latent)\u001b[0m\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/model/decoder.py?line=420'>421</a>\u001b[0m     prev_token, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(prev_token)\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/model/decoder.py?line=422'>423</a>\u001b[0m prev_token \u001b[39m=\u001b[39m prev_token\u001b[39m.\u001b[39munsqueeze(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m--> <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/model/decoder.py?line=423'>424</a>\u001b[0m lstm_output, lstm_hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(prev_token, prev_hidden)\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/model/decoder.py?line=425'>426</a>\u001b[0m attn_weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattn(lstm_output, encoder_outputs)\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/model/decoder.py?line=427'>428</a>\u001b[0m context \u001b[39m=\u001b[39m attn_weights\u001b[39m.\u001b[39mbmm(encoder_outputs\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py:759\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=754'>755</a>\u001b[0m     \u001b[39m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=755'>756</a>\u001b[0m     \u001b[39m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=756'>757</a>\u001b[0m     hx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m--> <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=758'>759</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_forward_args(\u001b[39minput\u001b[39;49m, hx, batch_sizes)\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=759'>760</a>\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=760'>761</a>\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers,\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=761'>762</a>\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py:685\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=678'>679</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_forward_args\u001b[39m(\u001b[39mself\u001b[39m,  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=679'>680</a>\u001b[0m                        \u001b[39minput\u001b[39m: Tensor,\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=680'>681</a>\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=681'>682</a>\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=682'>683</a>\u001b[0m                        ):\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=683'>684</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_input(\u001b[39minput\u001b[39m, batch_sizes)\n\u001b[0;32m--> <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=684'>685</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_hidden_size(hidden[\u001b[39m0\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_expected_hidden_size(\u001b[39minput\u001b[39;49m, batch_sizes),\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=685'>686</a>\u001b[0m                            \u001b[39m'\u001b[39;49m\u001b[39mExpected hidden[0] size \u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m, got \u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=686'>687</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_hidden_size(hidden[\u001b[39m1\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_expected_cell_size(\u001b[39minput\u001b[39m, batch_sizes),\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=687'>688</a>\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mExpected hidden[1] size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py:226\u001b[0m, in \u001b[0;36mRNNBase.check_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=222'>223</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_hidden_size\u001b[39m(\u001b[39mself\u001b[39m, hx: Tensor, expected_hidden_size: Tuple[\u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m],\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=223'>224</a>\u001b[0m                       msg: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mExpected hidden size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=224'>225</a>\u001b[0m     \u001b[39mif\u001b[39;00m hx\u001b[39m.\u001b[39msize() \u001b[39m!=\u001b[39m expected_hidden_size:\n\u001b[0;32m--> <a href='file:///home/patryk/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py?line=225'>226</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg\u001b[39m.\u001b[39mformat(expected_hidden_size, \u001b[39mlist\u001b[39m(hx\u001b[39m.\u001b[39msize())))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden[0] size (8, 2, 64), got [8, 3, 64]"
     ]
    }
   ],
   "source": [
    "output, hidden, attn_weights, attn_mu, attn_var = candidate_vae.decoder(\n",
    "    latent_vector, init_hidden, outputs, True\n",
    ")\n",
    "output = torch.argmax(output, dim=1).view(-1, 1)\n",
    "if general_config.embedder_name != EmbedderType.LANG:\n",
    "    output = candidate_vae.embed_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 236])\n"
     ]
    }
   ],
   "source": [
    "output, hidden, attn_weights, attn_mu, attn_var = candidate_vae.decoder(\n",
    "    output, hidden, outputs, False\n",
    ")\n",
    "print(output.shape)\n",
    "output = torch.argmax(output, dim=1).view(-1, 1)\n",
    "if general_config.embedder_name != EmbedderType.LANG:\n",
    "    output = candidate_vae.embed_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden, attn_weights, attn_mu, attn_var = candidate_vae.decoder(\n",
    "    output, hidden, outputs, False\n",
    ")\n",
    "output = torch.argmax(output, dim=1).view(-1, 1)\n",
    "if general_config.embedder_name != EmbedderType.LANG:\n",
    "    output = candidate_vae.embed_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check all together for batched input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    input_pad,\n",
    "    input_lengths,\n",
    "    target_pad,\n",
    "    mask,\n",
    "    max_target_length,\n",
    "    target_skills,\n",
    "    target_education,\n",
    "    target_languages,\n",
    ") = next(iter(dataloader))\n",
    "\n",
    "input_pad = input_pad.to(DEVICE)\n",
    "target_pad = target_pad.to(DEVICE)\n",
    "input_lengths = input_lengths.to(\"cpu\")\n",
    "\n",
    "outputs, attentions = candidate_vae.forward(input_pad, input_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(0)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BetaVaeTrainer...\n",
      "[2022-05-23 21:40:06,232] {trainer.py:225} INFO - Initializing BetaVaeTrainer...\n",
      "Done: BetaVaeTrainer initialized!\n",
      "[2022-05-23 21:40:06,235] {trainer.py:339} INFO - Done: BetaVaeTrainer initialized!\n"
     ]
    }
   ],
   "source": [
    "trainer = BetaVaeTrainer(\n",
    "    candidate_vae,\n",
    "    general_config,\n",
    "    trainer_config,\n",
    "    dataloader,\n",
    "    writer_tensorboard,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 0/128\n",
      "[2022-05-23 21:40:06,269] {trainer.py:661} INFO - Epoch 0/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/media/patryk/TOSHIBA EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/test_seq2seq.ipynb Cell 26'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/test_seq2seq.ipynb#ch0000024?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit()\n",
      "File \u001b[0;32m/media/patryk/TOSHIBA EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py:677\u001b[0m, in \u001b[0;36mBetaVaeTrainer.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=673'>674</a>\u001b[0m mask \u001b[39m=\u001b[39m mask\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvae\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=674'>675</a>\u001b[0m input_lengths \u001b[39m=\u001b[39m input_lengths\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=676'>677</a>\u001b[0m loss, recons_loss, kld_loss, kld_attn_loss, beta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step(\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=677'>678</a>\u001b[0m     input_pad,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=678'>679</a>\u001b[0m     input_lengths,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=679'>680</a>\u001b[0m     target_pad,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=680'>681</a>\u001b[0m     mask,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=681'>682</a>\u001b[0m     max_target_length,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=682'>683</a>\u001b[0m     target_skills,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=683'>684</a>\u001b[0m     target_education,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=684'>685</a>\u001b[0m     target_languages,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=685'>686</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=686'>687</a>\u001b[0m logging_losses[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=687'>688</a>\u001b[0m logging_losses[\u001b[39m\"\u001b[39m\u001b[39mrecons_loss\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m recons_loss\n",
      "File \u001b[0;32m/media/patryk/TOSHIBA EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py:597\u001b[0m, in \u001b[0;36mBetaVaeTrainer.train_step\u001b[0;34m(self, input_tensor, input_lengths, target_tensor, mask, max_target_length, target_skills, target_education, target_languages)\u001b[0m\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=587'>588</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneral_config\u001b[39m.\u001b[39membedder_name \u001b[39m!=\u001b[39m EmbedderType\u001b[39m.\u001b[39mLANG:\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=588'>589</a>\u001b[0m     decoder_input \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvae\u001b[39m.\u001b[39membed_output(decoder_input)\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=590'>591</a>\u001b[0m (\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=591'>592</a>\u001b[0m     batch_loss,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=592'>593</a>\u001b[0m     batch_recons_loss,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=593'>594</a>\u001b[0m     batch_kld_loss,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=594'>595</a>\u001b[0m     batch_kld_attn_loss,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=595'>596</a>\u001b[0m     n_total,\n\u001b[0;32m--> <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=596'>597</a>\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_function(\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=597'>598</a>\u001b[0m     decoder_output,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=598'>599</a>\u001b[0m     target_tensor[idx],\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=599'>600</a>\u001b[0m     mask,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=600'>601</a>\u001b[0m     mu,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=601'>602</a>\u001b[0m     log_var,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=602'>603</a>\u001b[0m     beta,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=603'>604</a>\u001b[0m     gamma,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=604'>605</a>\u001b[0m     attn_mu,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=605'>606</a>\u001b[0m     attn_var,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=606'>607</a>\u001b[0m     multitask_outputs,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=607'>608</a>\u001b[0m     adversarial_outputs,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=608'>609</a>\u001b[0m     adversarial_targets,\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=609'>610</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=611'>612</a>\u001b[0m loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_loss\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=612'>613</a>\u001b[0m recons_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_recons_loss\n",
      "File \u001b[0;32m/media/patryk/TOSHIBA EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py:427\u001b[0m, in \u001b[0;36mBetaVaeTrainer.loss_function\u001b[0;34m(self, decoder_output, target, mask, mu, log_var, beta, gamma, attn_mu, attn_var, multitask_outputs, adversarial_outputs, adversarial_targets)\u001b[0m\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=420'>421</a>\u001b[0m \u001b[39mif\u001b[39;00m multitask_outputs \u001b[39mand\u001b[39;00m adversarial_outputs:\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=421'>422</a>\u001b[0m     \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m multitask_outputs:\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=422'>423</a>\u001b[0m         \u001b[39m# First calc multitask losses\u001b[39;00m\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=423'>424</a>\u001b[0m         multitask_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisentangled_targets[key][\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=424'>425</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mlambda_mul\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=425'>426</a>\u001b[0m         ] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrossentropy_loss(\n\u001b[0;32m--> <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=426'>427</a>\u001b[0m             multitask_outputs[key], adversarial_targets[key]\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvae\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=427'>428</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=429'>430</a>\u001b[0m         \u001b[39m# Calculate entropy loss\u001b[39;00m\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=430'>431</a>\u001b[0m         \u001b[39m# \"It should be emphasized that, when we train the adversary,\u001b[39;00m\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=431'>432</a>\u001b[0m         \u001b[39m# the gradient is not propagated back to the autoencoder ...\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=432'>433</a>\u001b[0m         adversary_entropy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisentangled_targets[key][\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=433'>434</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mlambda_adv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///media/patryk/TOSHIBA%20EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/trainer/trainer.py?line=434'>435</a>\u001b[0m         ] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mentropy_loss(adversarial_outputs[key])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a62dc5c4e15874d230a4f396bb129d37f109e576af212db1e92385126337577"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
