{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First attempt to create a new representation method for a candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-05-22 19:57:52,995] {utils.py:147} INFO - Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "[2022-05-22 19:57:52,996] {utils.py:159} INFO - NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from model.encoder import CandidateEncoderConfig\n",
    "from model.decoder import CandidateDecoderConfig\n",
    "from model.candidate_vae import CandidateVAE\n",
    "from trainer.trainer import BetaVaeTrainer, TrainerConfig\n",
    "from config.general_config import GeneralConfig\n",
    "from model.embedder import EmbedderType\n",
    "from dataset.utils import pad_collate\n",
    "from dataset.dataset import SellersDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "with open(\"config/config.yaml\", \"r\") as file:\n",
    "    try:\n",
    "        config = yaml.safe_load(file)[\"vae\"]\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "general_config = GeneralConfig(**config[\"general\"])\n",
    "encoder_config = CandidateEncoderConfig(**config[\"encoder\"], **config[\"general\"])\n",
    "\n",
    "decoder_config = CandidateDecoderConfig(**config[\"decoder\"], **config[\"general\"])\n",
    "\n",
    "trainer_config = TrainerConfig(**config[\"trainer\"], **config[\"general\"])\n",
    "\n",
    "log_dir = os.path.join(general_config.checkpoints_dir, \"runs\")\n",
    "\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "writer_tensorboard = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 63659), started 0:50:32 ago. (Use '!kill 63659' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-99ece50a40835256\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-99ece50a40835256\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir $log_dir --port=6008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset\n",
      "[2022-05-22 19:57:53,621] {dataset.py:142} INFO - Preparing dataset\n",
      "Detecting languages:\n",
      "[2022-05-22 19:57:53,622] {dataset.py:169} INFO - Detecting languages:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 12.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected languages:\n",
      "[2022-05-22 19:57:53,933] {dataset.py:174} INFO - Detected languages:\n",
      "lang\n",
      "en    4\n",
      "Name: lang, dtype: int64\n",
      "[2022-05-22 19:57:53,934] {dataset.py:175} INFO - lang\n",
      "en    4\n",
      "Name: lang, dtype: int64\n",
      "Removing rows not written in english\n",
      "[2022-05-22 19:57:53,935] {dataset.py:176} INFO - Removing rows not written in english\n",
      "Removed 0 rows\n",
      "[2022-05-22 19:57:53,935] {dataset.py:180} INFO - Removed 0 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 5769.33it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 6831.11it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 1772.74it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11715.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding language for languages_str\n",
      "[2022-05-22 19:57:53,947] {dataset.py:356} INFO - Adding language for languages_str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 20410.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding language for education_str\n",
      "[2022-05-22 19:57:53,948] {dataset.py:356} INFO - Adding language for education_str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 22250.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding language for skills_str\n",
      "[2022-05-22 19:57:53,950] {dataset.py:356} INFO - Adding language for skills_str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 15033.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding language for description_str\n",
      "[2022-05-22 19:57:53,951] {dataset.py:356} INFO - Adding language for description_str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 9737.21it/s]\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "dataset = SellersDataset(\n",
    "    embedder_name=config[\"general\"][\"embedder_name\"],\n",
    "    data_path=config[\"general\"][\"data_path\"],\n",
    "    device=DEVICE,\n",
    ")\n",
    "dataset.prepare_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=general_config.batch_size,\n",
    "    collate_fn=pad_collate(dataset.vocab.pad_token),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models to test them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_vae = CandidateVAE(\n",
    "    general_config, encoder_config, decoder_config, dataset.vocab, dataset.embedder\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check encoder / decoder separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/patryk/TOSHIBA EXT/Studia/SztucznaInteligencja/PracaMagisterska/master-thesis/seq2seq/dataset/dataset.py:338: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row[\"skills_str\"] = (\n"
     ]
    }
   ],
   "source": [
    "input_pad, input_lengths, target_pad, mask, max_target_length = next(iter(dataloader))\n",
    "\n",
    "input_pad = input_pad.to(DEVICE)\n",
    "target_pad = target_pad.to(DEVICE)\n",
    "input_lengths = input_lengths.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, var, outputs, (hn, cn) = candidate_vae.encoder(input_pad, input_lengths)\n",
    "mu.shape, var.shape, outputs.shape\n",
    "\n",
    "latent_vector = candidate_vae.decoder.reparameterize(mu, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_hidden = candidate_vae.decoder.init_hidden_cell(general_config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden, attn_weights, attn_mu, attn_var = candidate_vae.decoder(\n",
    "    latent_vector, init_hidden, outputs, True\n",
    ")\n",
    "output = torch.argmax(output, dim=1).view(-1, 1)\n",
    "if general_config.embedder_name != EmbedderType.LANG:\n",
    "    output = candidate_vae.embed_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 220])\n"
     ]
    }
   ],
   "source": [
    "output, hidden, attn_weights, attn_mu, attn_var = candidate_vae.decoder(\n",
    "    output, hidden, outputs, False\n",
    ")\n",
    "print(output.shape)\n",
    "output = torch.argmax(output, dim=1).view(-1, 1)\n",
    "if general_config.embedder_name != EmbedderType.LANG:\n",
    "    output = candidate_vae.embed_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden, attn_weights, attn_mu, attn_var = candidate_vae.decoder(\n",
    "    output, hidden, outputs, False\n",
    ")\n",
    "output = torch.argmax(output, dim=1).view(-1, 1)\n",
    "if general_config.embedder_name != EmbedderType.LANG:\n",
    "    output = candidate_vae.embed_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check all together for batched input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pad, input_lengths, target_pad, mask, max_target_length = next(iter(dataloader))\n",
    "\n",
    "input_pad = input_pad.to(DEVICE)\n",
    "target_pad = target_pad.to(DEVICE)\n",
    "input_lengths = input_lengths.to(\"cpu\")\n",
    "\n",
    "outputs, attentions = candidate_vae.forward(input_pad, input_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BetaVaeTrainer...\n",
      "[2022-05-22 19:58:20,575] {trainer.py:163} INFO - Initializing BetaVaeTrainer...\n",
      "Done: BetaVaeTrainer initialized!\n",
      "[2022-05-22 19:58:20,576] {trainer.py:193} INFO - Done: BetaVaeTrainer initialized!\n"
     ]
    }
   ],
   "source": [
    "encoder_optimizer = torch.optim.Adam(\n",
    "    candidate_vae.encoder.parameters(), lr=general_config.encoder_lr\n",
    ")\n",
    "decoder_optimizer = torch.optim.Adam(\n",
    "    candidate_vae.decoder.parameters(), lr=general_config.decoder_lr\n",
    ")\n",
    "\n",
    "trainer = BetaVaeTrainer(\n",
    "    candidate_vae,\n",
    "    encoder_optimizer,\n",
    "    decoder_optimizer,\n",
    "    general_config,\n",
    "    trainer_config,\n",
    "    dataloader,\n",
    "    writer_tensorboard,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 0/128\n",
      "[2022-05-22 19:58:23,377] {trainer.py:426} INFO - Epoch 0/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:55<00:55, 55.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [01:04<00:55, 55.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2; Percent complete: 1.2%; Average loss: 1.9522; Average recons_loss: 1.9522; Average kld_loss: 0.0000; Average kld_attn_loss: 0.1151\n",
      "[2022-05-22 19:59:27,621] {trainer.py:500} INFO - Iteration: 2; Percent complete: 1.2%; Average loss: 1.9522; Average recons_loss: 1.9522; Average kld_loss: 0.0000; Average kld_attn_loss: 0.1151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:04<00:00, 32.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "[2022-05-22 19:59:27,752] {trainer.py:426} INFO - Epoch 1/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:53<00:53, 53.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [01:01<00:53, 53.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4; Percent complete: 2.4%; Average loss: 1.9461; Average recons_loss: 1.9461; Average kld_loss: 0.0000; Average kld_attn_loss: 0.1152\n",
      "[2022-05-22 20:00:29,423] {trainer.py:500} INFO - Iteration: 4; Percent complete: 2.4%; Average loss: 1.9461; Average recons_loss: 1.9461; Average kld_loss: 0.0000; Average kld_attn_loss: 0.1152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:01<00:00, 30.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/128\n",
      "[2022-05-22 20:00:29,550] {trainer.py:426} INFO - Epoch 2/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:53<00:53, 53.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [01:02<00:53, 53.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6; Percent complete: 3.5%; Average loss: 1.9805; Average recons_loss: 1.9611; Average kld_loss: 0.0000; Average kld_attn_loss: 0.1152\n",
      "[2022-05-22 20:01:31,973] {trainer.py:500} INFO - Iteration: 6; Percent complete: 3.5%; Average loss: 1.9805; Average recons_loss: 1.9611; Average kld_loss: 0.0000; Average kld_attn_loss: 0.1152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:02<00:00, 31.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/128\n",
      "[2022-05-22 20:01:32,106] {trainer.py:426} INFO - Epoch 3/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 6\n"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a62dc5c4e15874d230a4f396bb129d37f109e576af212db1e92385126337577"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
